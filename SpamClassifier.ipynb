{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CIS 545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ea84daade4a467d9b4e8249067cf7a2d",
     "grade": false,
     "grade_id": "cell-a223868a702efb2d",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Homework 5: Spam Classification in SciKit-Learn and TensorFlow\n",
    "\n",
    "This assignment uses data from https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection\n",
    "\n",
    "Data processing was inspired by https://www.kaggle.com/overflow012/d/uciml/sms-spam-collection-dataset/text-preprocessing-classification\n",
    "\n",
    "The code below gives you a helper function and reads in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This function returns the k most frequently appearing keywords in the dataframe\n",
    "def top_k(data_df, vec, k):\n",
    "    X = vec.fit_transform(data_df['sms'].values)\n",
    "    labels = vec.get_feature_names()    \n",
    "    return pd.DataFrame(columns = labels, data = X.toarray()).sum().sort_values(ascending = False)[:k]\n",
    "\n",
    "sms_df = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "sms_df.columns = ['class', 'sms', 'a', 'b', 'c']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>sms</th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thatåÕs the way u feel. ThatåÕs the wa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ham</td>\n",
       "      <td>Is that seriously how you spell his name?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ham</td>\n",
       "      <td>IÛ÷m going to try for 2 months ha ha only joking</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ham</td>\n",
       "      <td>So Ì_ pay first lar... Then when is da stock c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aft i finish my lunch then i go str down lor. ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ffffffffff. Alright no way I can meet up with ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ham</td>\n",
       "      <td>Just forced myself to eat a slice. I'm really ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lol your always so convincing.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ham</td>\n",
       "      <td>Did you catch the bus ? Are you frying an egg ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm back &amp;amp; we're packing the car now, I'll...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ahhh. Work. I vaguely remember that! What does...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>ham</td>\n",
       "      <td>Armand says get your ass over to epsilon</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>ham</td>\n",
       "      <td>U still havent got urself a jacket ah?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5544</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm taking derek &amp;amp; taylor to walmart, if I...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hi its in durban are you still on this number</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ic. There are a lotta childporn cars then.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>ham</td>\n",
       "      <td>No, I was trying it all weekend ;V</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>ham</td>\n",
       "      <td>You know, wot people wear. T shirts, jumpers, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>ham</td>\n",
       "      <td>Cool, what time you think you can get here?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wen did you get so spiritual and deep. That's ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5552</th>\n",
       "      <td>ham</td>\n",
       "      <td>Have a safe trip to Nigeria. Wish you happines...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hahaha..use your brain dear</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>ham</td>\n",
       "      <td>Well keep in mind I've only got enough gas for...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yeh. Indians was nice. Tho it did kane me off ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes i have. So that's why u texted. Pshew...mi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5557</th>\n",
       "      <td>ham</td>\n",
       "      <td>No. I meant the calculation is the same. That ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>ham</td>\n",
       "      <td>if you aren't here in the next  &amp;lt;#&amp;gt;  hou...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5560</th>\n",
       "      <td>ham</td>\n",
       "      <td>Anything lor. Juz both of us lor.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>ham</td>\n",
       "      <td>Get me out of this dump heap. My mom decided t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lor... Sony ericsson salesman... I ask shuh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ard 6 like dat lor.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>ham</td>\n",
       "      <td>Why don't you wait 'til at least wednesday to ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>ham</td>\n",
       "      <td>Huh y lei...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>spam</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class                                                sms    a    b    c\n",
       "0      ham  Go until jurong point, crazy.. Available only ...  NaN  NaN  NaN\n",
       "1      ham                      Ok lar... Joking wif u oni...  NaN  NaN  NaN\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...  NaN  NaN  NaN\n",
       "3      ham  U dun say so early hor... U c already then say...  NaN  NaN  NaN\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...  NaN  NaN  NaN\n",
       "5     spam  FreeMsg Hey there darling it's been 3 week's n...  NaN  NaN  NaN\n",
       "6      ham  Even my brother is not like to speak with me. ...  NaN  NaN  NaN\n",
       "7      ham  As per your request 'Melle Melle (Oru Minnamin...  NaN  NaN  NaN\n",
       "8     spam  WINNER!! As a valued network customer you have...  NaN  NaN  NaN\n",
       "9     spam  Had your mobile 11 months or more? U R entitle...  NaN  NaN  NaN\n",
       "10     ham  I'm gonna be home soon and i don't want to tal...  NaN  NaN  NaN\n",
       "11    spam  SIX chances to win CASH! From 100 to 20,000 po...  NaN  NaN  NaN\n",
       "12    spam  URGENT! You have won a 1 week FREE membership ...  NaN  NaN  NaN\n",
       "13     ham  I've been searching for the right words to tha...  NaN  NaN  NaN\n",
       "14     ham                I HAVE A DATE ON SUNDAY WITH WILL!!  NaN  NaN  NaN\n",
       "15    spam  XXXMobileMovieClub: To use your credit, click ...  NaN  NaN  NaN\n",
       "16     ham                         Oh k...i'm watching here:)  NaN  NaN  NaN\n",
       "17     ham  Eh u remember how 2 spell his name... Yes i di...  NaN  NaN  NaN\n",
       "18     ham  Fine if thatåÕs the way u feel. ThatåÕs the wa...  NaN  NaN  NaN\n",
       "19    spam  England v Macedonia - dont miss the goals/team...  NaN  NaN  NaN\n",
       "20     ham          Is that seriously how you spell his name?  NaN  NaN  NaN\n",
       "21     ham  IÛ÷m going to try for 2 months ha ha only joking  NaN  NaN  NaN\n",
       "22     ham  So Ì_ pay first lar... Then when is da stock c...  NaN  NaN  NaN\n",
       "23     ham  Aft i finish my lunch then i go str down lor. ...  NaN  NaN  NaN\n",
       "24     ham  Ffffffffff. Alright no way I can meet up with ...  NaN  NaN  NaN\n",
       "25     ham  Just forced myself to eat a slice. I'm really ...  NaN  NaN  NaN\n",
       "26     ham                     Lol your always so convincing.  NaN  NaN  NaN\n",
       "27     ham  Did you catch the bus ? Are you frying an egg ...  NaN  NaN  NaN\n",
       "28     ham  I'm back &amp; we're packing the car now, I'll...  NaN  NaN  NaN\n",
       "29     ham  Ahhh. Work. I vaguely remember that! What does...  NaN  NaN  NaN\n",
       "...    ...                                                ...  ...  ...  ...\n",
       "5542   ham           Armand says get your ass over to epsilon  NaN  NaN  NaN\n",
       "5543   ham             U still havent got urself a jacket ah?  NaN  NaN  NaN\n",
       "5544   ham  I'm taking derek &amp; taylor to walmart, if I...  NaN  NaN  NaN\n",
       "5545   ham      Hi its in durban are you still on this number  NaN  NaN  NaN\n",
       "5546   ham         Ic. There are a lotta childporn cars then.  NaN  NaN  NaN\n",
       "5547  spam  Had your contract mobile 11 Mnths? Latest Moto...  NaN  NaN  NaN\n",
       "5548   ham                 No, I was trying it all weekend ;V  NaN  NaN  NaN\n",
       "5549   ham  You know, wot people wear. T shirts, jumpers, ...  NaN  NaN  NaN\n",
       "5550   ham        Cool, what time you think you can get here?  NaN  NaN  NaN\n",
       "5551   ham  Wen did you get so spiritual and deep. That's ...  NaN  NaN  NaN\n",
       "5552   ham  Have a safe trip to Nigeria. Wish you happines...  NaN  NaN  NaN\n",
       "5553   ham                        Hahaha..use your brain dear  NaN  NaN  NaN\n",
       "5554   ham  Well keep in mind I've only got enough gas for...  NaN  NaN  NaN\n",
       "5555   ham  Yeh. Indians was nice. Tho it did kane me off ...  NaN  NaN  NaN\n",
       "5556   ham  Yes i have. So that's why u texted. Pshew...mi...  NaN  NaN  NaN\n",
       "5557   ham  No. I meant the calculation is the same. That ...  NaN  NaN  NaN\n",
       "5558   ham                             Sorry, I'll call later  NaN  NaN  NaN\n",
       "5559   ham  if you aren't here in the next  &lt;#&gt;  hou...  NaN  NaN  NaN\n",
       "5560   ham                  Anything lor. Juz both of us lor.  NaN  NaN  NaN\n",
       "5561   ham  Get me out of this dump heap. My mom decided t...  NaN  NaN  NaN\n",
       "5562   ham  Ok lor... Sony ericsson salesman... I ask shuh...  NaN  NaN  NaN\n",
       "5563   ham                                Ard 6 like dat lor.  NaN  NaN  NaN\n",
       "5564   ham  Why don't you wait 'til at least wednesday to ...  NaN  NaN  NaN\n",
       "5565   ham                                       Huh y lei...  NaN  NaN  NaN\n",
       "5566  spam  REMINDER FROM O2: To get 2.50 pounds free call...  NaN  NaN  NaN\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...  NaN  NaN  NaN\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?  NaN  NaN  NaN\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...  NaN  NaN  NaN\n",
       "5570   ham  The guy did some bitching but I acted like i'd...  NaN  NaN  NaN\n",
       "5571   ham                         Rofl. Its true to its name  NaN  NaN  NaN\n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "53d05d307656def06b896717f34e2c92",
     "grade": false,
     "grade_id": "cell-a5eee818a0480a64",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Step 1.1 Data Wrangling and Inspection\n",
    "\n",
    "Clean up `sms_df`.  Delete 'a', 'b', 'c', lowercase the sms text, add a column 'length'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "aa185e3286b68fae001525c33514f18e",
     "grade": false,
     "grade_id": "cell-7e8173b18ef4a793",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>sms</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thatåÕs the way u feel. ThatåÕs the wa...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ham</td>\n",
       "      <td>Is that seriously how you spell his name?</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ham</td>\n",
       "      <td>IÛ÷m going to try for 2 months ha ha only joking</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ham</td>\n",
       "      <td>So Ì_ pay first lar... Then when is da stock c...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aft i finish my lunch then i go str down lor. ...</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ffffffffff. Alright no way I can meet up with ...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ham</td>\n",
       "      <td>Just forced myself to eat a slice. I'm really ...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lol your always so convincing.</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ham</td>\n",
       "      <td>Did you catch the bus ? Are you frying an egg ...</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm back &amp;amp; we're packing the car now, I'll...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ahhh. Work. I vaguely remember that! What does...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>ham</td>\n",
       "      <td>Armand says get your ass over to epsilon</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>ham</td>\n",
       "      <td>U still havent got urself a jacket ah?</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5544</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm taking derek &amp;amp; taylor to walmart, if I...</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hi its in durban are you still on this number</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ic. There are a lotta childporn cars then.</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>ham</td>\n",
       "      <td>No, I was trying it all weekend ;V</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>ham</td>\n",
       "      <td>You know, wot people wear. T shirts, jumpers, ...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>ham</td>\n",
       "      <td>Cool, what time you think you can get here?</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wen did you get so spiritual and deep. That's ...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5552</th>\n",
       "      <td>ham</td>\n",
       "      <td>Have a safe trip to Nigeria. Wish you happines...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hahaha..use your brain dear</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>ham</td>\n",
       "      <td>Well keep in mind I've only got enough gas for...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yeh. Indians was nice. Tho it did kane me off ...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes i have. So that's why u texted. Pshew...mi...</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5557</th>\n",
       "      <td>ham</td>\n",
       "      <td>No. I meant the calculation is the same. That ...</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>ham</td>\n",
       "      <td>if you aren't here in the next  &amp;lt;#&amp;gt;  hou...</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5560</th>\n",
       "      <td>ham</td>\n",
       "      <td>Anything lor. Juz both of us lor.</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>ham</td>\n",
       "      <td>Get me out of this dump heap. My mom decided t...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lor... Sony ericsson salesman... I ask shuh...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ard 6 like dat lor.</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>ham</td>\n",
       "      <td>Why don't you wait 'til at least wednesday to ...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>ham</td>\n",
       "      <td>Huh y lei...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>spam</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class                                                sms  length\n",
       "0      ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1      ham                      Ok lar... Joking wif u oni...      29\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3      ham  U dun say so early hor... U c already then say...      49\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...      61\n",
       "5     spam  FreeMsg Hey there darling it's been 3 week's n...     148\n",
       "6      ham  Even my brother is not like to speak with me. ...      77\n",
       "7      ham  As per your request 'Melle Melle (Oru Minnamin...     160\n",
       "8     spam  WINNER!! As a valued network customer you have...     158\n",
       "9     spam  Had your mobile 11 months or more? U R entitle...     154\n",
       "10     ham  I'm gonna be home soon and i don't want to tal...     109\n",
       "11    spam  SIX chances to win CASH! From 100 to 20,000 po...     136\n",
       "12    spam  URGENT! You have won a 1 week FREE membership ...     156\n",
       "13     ham  I've been searching for the right words to tha...     196\n",
       "14     ham                I HAVE A DATE ON SUNDAY WITH WILL!!      35\n",
       "15    spam  XXXMobileMovieClub: To use your credit, click ...     149\n",
       "16     ham                         Oh k...i'm watching here:)      26\n",
       "17     ham  Eh u remember how 2 spell his name... Yes i di...      81\n",
       "18     ham  Fine if thatåÕs the way u feel. ThatåÕs the wa...      58\n",
       "19    spam  England v Macedonia - dont miss the goals/team...     156\n",
       "20     ham          Is that seriously how you spell his name?      41\n",
       "21     ham  IÛ÷m going to try for 2 months ha ha only joking      49\n",
       "22     ham  So Ì_ pay first lar... Then when is da stock c...      53\n",
       "23     ham  Aft i finish my lunch then i go str down lor. ...      88\n",
       "24     ham  Ffffffffff. Alright no way I can meet up with ...      57\n",
       "25     ham  Just forced myself to eat a slice. I'm really ...     144\n",
       "26     ham                     Lol your always so convincing.      30\n",
       "27     ham  Did you catch the bus ? Are you frying an egg ...     134\n",
       "28     ham  I'm back &amp; we're packing the car now, I'll...      75\n",
       "29     ham  Ahhh. Work. I vaguely remember that! What does...      64\n",
       "...    ...                                                ...     ...\n",
       "5542   ham           Armand says get your ass over to epsilon      40\n",
       "5543   ham             U still havent got urself a jacket ah?      38\n",
       "5544   ham  I'm taking derek &amp; taylor to walmart, if I...     154\n",
       "5545   ham      Hi its in durban are you still on this number      45\n",
       "5546   ham         Ic. There are a lotta childporn cars then.      42\n",
       "5547  spam  Had your contract mobile 11 Mnths? Latest Moto...     160\n",
       "5548   ham                 No, I was trying it all weekend ;V      34\n",
       "5549   ham  You know, wot people wear. T shirts, jumpers, ...      87\n",
       "5550   ham        Cool, what time you think you can get here?      43\n",
       "5551   ham  Wen did you get so spiritual and deep. That's ...      51\n",
       "5552   ham  Have a safe trip to Nigeria. Wish you happines...      91\n",
       "5553   ham                        Hahaha..use your brain dear      27\n",
       "5554   ham  Well keep in mind I've only got enough gas for...      98\n",
       "5555   ham  Yeh. Indians was nice. Tho it did kane me off ...     153\n",
       "5556   ham  Yes i have. So that's why u texted. Pshew...mi...      63\n",
       "5557   ham  No. I meant the calculation is the same. That ...     273\n",
       "5558   ham                             Sorry, I'll call later      22\n",
       "5559   ham  if you aren't here in the next  &lt;#&gt;  hou...      66\n",
       "5560   ham                  Anything lor. Juz both of us lor.      33\n",
       "5561   ham  Get me out of this dump heap. My mom decided t...      70\n",
       "5562   ham  Ok lor... Sony ericsson salesman... I ask shuh...      96\n",
       "5563   ham                                Ard 6 like dat lor.      19\n",
       "5564   ham  Why don't you wait 'til at least wednesday to ...      67\n",
       "5565   ham                                       Huh y lei...      12\n",
       "5566  spam  REMINDER FROM O2: To get 2.50 pounds free call...     147\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...     161\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?      37\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...      57\n",
       "5570   ham  The guy did some bitching but I acted like i'd...     125\n",
       "5571   ham                         Rofl. Its true to its name      26\n",
       "\n",
       "[5572 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Data wrangling / cleaning\n",
    "sms_df = sms_df[['class','sms']]\n",
    "\n",
    "sms_df['length'] = sms_df['sms'].apply(lambda x: len(str(x)))\n",
    "sms_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7e8cef8fdd4404d4d6a16e806677408a",
     "grade": false,
     "grade_id": "cell-842a98f320c23038",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "After you’ve done this, step through these cells to see how the input data divides between ‘spam’ texts and ‘ham’ (non-spam) texts.  You should note that the spam has certain terms, e.g., ‘winner’, that don’t appear as frequently in “ham.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "ac17a9e65115f5b96ffb2986ff65b5f2",
     "grade": true,
     "grade_id": "cell-3d121bf137cc9f99",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>sms</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a 1 week FREE membership ...</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u remember how 2 spell his name... Yes i di...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thatåÕs the way u feel. ThatåÕs the wa...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ham</td>\n",
       "      <td>Is that seriously how you spell his name?</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ham</td>\n",
       "      <td>IÛ÷m going to try for 2 months ha ha only joking</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ham</td>\n",
       "      <td>So Ì_ pay first lar... Then when is da stock c...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aft i finish my lunch then i go str down lor. ...</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ffffffffff. Alright no way I can meet up with ...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ham</td>\n",
       "      <td>Just forced myself to eat a slice. I'm really ...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lol your always so convincing.</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ham</td>\n",
       "      <td>Did you catch the bus ? Are you frying an egg ...</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm back &amp;amp; we're packing the car now, I'll...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ahhh. Work. I vaguely remember that! What does...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>ham</td>\n",
       "      <td>Armand says get your ass over to epsilon</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>ham</td>\n",
       "      <td>U still havent got urself a jacket ah?</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5544</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm taking derek &amp;amp; taylor to walmart, if I...</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hi its in durban are you still on this number</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ic. There are a lotta childporn cars then.</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your contract mobile 11 Mnths? Latest Moto...</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>ham</td>\n",
       "      <td>No, I was trying it all weekend ;V</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>ham</td>\n",
       "      <td>You know, wot people wear. T shirts, jumpers, ...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>ham</td>\n",
       "      <td>Cool, what time you think you can get here?</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wen did you get so spiritual and deep. That's ...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5552</th>\n",
       "      <td>ham</td>\n",
       "      <td>Have a safe trip to Nigeria. Wish you happines...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hahaha..use your brain dear</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>ham</td>\n",
       "      <td>Well keep in mind I've only got enough gas for...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yeh. Indians was nice. Tho it did kane me off ...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes i have. So that's why u texted. Pshew...mi...</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5557</th>\n",
       "      <td>ham</td>\n",
       "      <td>No. I meant the calculation is the same. That ...</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>ham</td>\n",
       "      <td>if you aren't here in the next  &amp;lt;#&amp;gt;  hou...</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5560</th>\n",
       "      <td>ham</td>\n",
       "      <td>Anything lor. Juz both of us lor.</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>ham</td>\n",
       "      <td>Get me out of this dump heap. My mom decided t...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lor... Sony ericsson salesman... I ask shuh...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ard 6 like dat lor.</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>ham</td>\n",
       "      <td>Why don't you wait 'til at least wednesday to ...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>ham</td>\n",
       "      <td>Huh y lei...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>spam</td>\n",
       "      <td>REMINDER FROM O2: To get 2.50 pounds free call...</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class                                                sms  length\n",
       "0      ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1      ham                      Ok lar... Joking wif u oni...      29\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...     155\n",
       "3      ham  U dun say so early hor... U c already then say...      49\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...      61\n",
       "5     spam  FreeMsg Hey there darling it's been 3 week's n...     148\n",
       "6      ham  Even my brother is not like to speak with me. ...      77\n",
       "7      ham  As per your request 'Melle Melle (Oru Minnamin...     160\n",
       "8     spam  WINNER!! As a valued network customer you have...     158\n",
       "9     spam  Had your mobile 11 months or more? U R entitle...     154\n",
       "10     ham  I'm gonna be home soon and i don't want to tal...     109\n",
       "11    spam  SIX chances to win CASH! From 100 to 20,000 po...     136\n",
       "12    spam  URGENT! You have won a 1 week FREE membership ...     156\n",
       "13     ham  I've been searching for the right words to tha...     196\n",
       "14     ham                I HAVE A DATE ON SUNDAY WITH WILL!!      35\n",
       "15    spam  XXXMobileMovieClub: To use your credit, click ...     149\n",
       "16     ham                         Oh k...i'm watching here:)      26\n",
       "17     ham  Eh u remember how 2 spell his name... Yes i di...      81\n",
       "18     ham  Fine if thatåÕs the way u feel. ThatåÕs the wa...      58\n",
       "19    spam  England v Macedonia - dont miss the goals/team...     156\n",
       "20     ham          Is that seriously how you spell his name?      41\n",
       "21     ham  IÛ÷m going to try for 2 months ha ha only joking      49\n",
       "22     ham  So Ì_ pay first lar... Then when is da stock c...      53\n",
       "23     ham  Aft i finish my lunch then i go str down lor. ...      88\n",
       "24     ham  Ffffffffff. Alright no way I can meet up with ...      57\n",
       "25     ham  Just forced myself to eat a slice. I'm really ...     144\n",
       "26     ham                     Lol your always so convincing.      30\n",
       "27     ham  Did you catch the bus ? Are you frying an egg ...     134\n",
       "28     ham  I'm back &amp; we're packing the car now, I'll...      75\n",
       "29     ham  Ahhh. Work. I vaguely remember that! What does...      64\n",
       "...    ...                                                ...     ...\n",
       "5542   ham           Armand says get your ass over to epsilon      40\n",
       "5543   ham             U still havent got urself a jacket ah?      38\n",
       "5544   ham  I'm taking derek &amp; taylor to walmart, if I...     154\n",
       "5545   ham      Hi its in durban are you still on this number      45\n",
       "5546   ham         Ic. There are a lotta childporn cars then.      42\n",
       "5547  spam  Had your contract mobile 11 Mnths? Latest Moto...     160\n",
       "5548   ham                 No, I was trying it all weekend ;V      34\n",
       "5549   ham  You know, wot people wear. T shirts, jumpers, ...      87\n",
       "5550   ham        Cool, what time you think you can get here?      43\n",
       "5551   ham  Wen did you get so spiritual and deep. That's ...      51\n",
       "5552   ham  Have a safe trip to Nigeria. Wish you happines...      91\n",
       "5553   ham                        Hahaha..use your brain dear      27\n",
       "5554   ham  Well keep in mind I've only got enough gas for...      98\n",
       "5555   ham  Yeh. Indians was nice. Tho it did kane me off ...     153\n",
       "5556   ham  Yes i have. So that's why u texted. Pshew...mi...      63\n",
       "5557   ham  No. I meant the calculation is the same. That ...     273\n",
       "5558   ham                             Sorry, I'll call later      22\n",
       "5559   ham  if you aren't here in the next  &lt;#&gt;  hou...      66\n",
       "5560   ham                  Anything lor. Juz both of us lor.      33\n",
       "5561   ham  Get me out of this dump heap. My mom decided t...      70\n",
       "5562   ham  Ok lor... Sony ericsson salesman... I ask shuh...      96\n",
       "5563   ham                                Ard 6 like dat lor.      19\n",
       "5564   ham  Why don't you wait 'til at least wednesday to ...      67\n",
       "5565   ham                                       Huh y lei...      12\n",
       "5566  spam  REMINDER FROM O2: To get 2.50 pounds free call...     147\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...     161\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?      37\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...      57\n",
       "5570   ham  The guy did some bitching but I acted like i'd...     125\n",
       "5571   ham                         Rofl. Its true to its name      26\n",
       "\n",
       "[5572 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sms_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "236575d8f940bc4033d5ba411535d659",
     "grade": true,
     "grade_id": "cell-9a1deed737f919f6",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">length</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ham</th>\n",
       "      <td>4825.0</td>\n",
       "      <td>71.023627</td>\n",
       "      <td>58.016023</td>\n",
       "      <td>2.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>910.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spam</th>\n",
       "      <td>747.0</td>\n",
       "      <td>138.866131</td>\n",
       "      <td>29.183082</td>\n",
       "      <td>13.0</td>\n",
       "      <td>132.5</td>\n",
       "      <td>149.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       length                                                         \n",
       "        count        mean        std   min    25%    50%    75%    max\n",
       "class                                                                 \n",
       "ham    4825.0   71.023627  58.016023   2.0   33.0   52.0   92.0  910.0\n",
       "spam    747.0  138.866131  29.183082  13.0  132.5  149.0  157.0  224.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(sms_df.groupby('class').describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "672d555daaa0bd12b7a933b32aee8938",
     "grade": false,
     "grade_id": "cell-7c0f00dc70205f00",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Step 1.2. Vectorizing the Text\n",
    "\n",
    "`scikit-learn` has a handy `CountVectorizer` that builds a (sparse) matrix of word counts, drops stop words and even does stemming.  See:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "\n",
    "The code below builds document vectors automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec = CountVectorizer(decode_error = 'ignore', stop_words = 'english')\n",
    "X = vec.fit_transform(sms_df['sms'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "34bba3dc3cb106e1de9ac1deb73a85a3",
     "grade": false,
     "grade_id": "cell-e3434690042e1d44",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Step 1.2.1 What are the frequent words? What are frequent patterns?\n",
    "\n",
    "Run the next couple of cells to see the top-30 words in spam and in ham.  If you look, you should see numbers and parts of URLs (“www”, “com”) in the spam.  Perhaps we need to get rid of these altogether.  However, the URLs and numbers are highly varied, so we would like to map all URLs to one feature, and all numbers to one feature. \n",
    "\n",
    "In the cell below store the index of \"www\" as `www` and the index of \"com\" as `com`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c151934539f597650509065897f62072",
     "grade": false,
     "grade_id": "cell-2a578c160b892b68",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8274\n",
      "2089\n"
     ]
    }
   ],
   "source": [
    "www = 0\n",
    "com = 0\n",
    "for i in range(len(vec.get_feature_names())):\n",
    "    if vec.get_feature_names()[i] == 'www':\n",
    "        www = i\n",
    "    elif vec.get_feature_names()[i] == 'com':\n",
    "        com = i\n",
    "print(www)\n",
    "print(com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "dc945d639e857c981807f2dd268192ab",
     "grade": true,
     "grade_id": "cell-7806b810412a1d82",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "free          224\n",
       "txt           163\n",
       "ur            144\n",
       "mobile        127\n",
       "text          125\n",
       "stop          121\n",
       "claim         113\n",
       "reply         104\n",
       "www            98\n",
       "prize          93\n",
       "just           78\n",
       "cash           76\n",
       "won            76\n",
       "uk             74\n",
       "150p           71\n",
       "send           70\n",
       "new            69\n",
       "nokia          67\n",
       "win            64\n",
       "urgent         63\n",
       "tone           60\n",
       "week           60\n",
       "50             57\n",
       "contact        56\n",
       "service        56\n",
       "msg            54\n",
       "com            54\n",
       "18             51\n",
       "16             51\n",
       "guaranteed     50\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_spam = top_k(sms_df[sms_df['class'] == 'spam'], vec, 30)\n",
    "display(top_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "77a16e4d207020f7f1897b2cba8e294d",
     "grade": true,
     "grade_id": "cell-d24b1e1c9c02021f",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gt       318\n",
       "lt       316\n",
       "just     293\n",
       "ok       287\n",
       "ll       265\n",
       "ur       241\n",
       "know     236\n",
       "good     233\n",
       "got      232\n",
       "like     232\n",
       "come     227\n",
       "day      209\n",
       "time     201\n",
       "love     199\n",
       "going    169\n",
       "home     165\n",
       "want     164\n",
       "lor      162\n",
       "need     158\n",
       "sorry    157\n",
       "don      151\n",
       "da       150\n",
       "today    139\n",
       "later    135\n",
       "dont     132\n",
       "did      129\n",
       "send     129\n",
       "think    128\n",
       "pls      123\n",
       "hi       122\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_ham = top_k(sms_df[sms_df['class'] == 'ham'], vec, 30)\n",
    "display(top_ham)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6d0e6dd707ad958a81ce2a0dcece1faa",
     "grade": false,
     "grade_id": "cell-c4c6255d8ac33f78",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Step 1.2.2 Regularize URLs and Numbers\n",
    "\n",
    "Let’s replace all URL patterns, and all numbers, with a single text token (“_url_” and “_number_”).  To do this, simply pass the appropriate column of your DataFrame to `regularize_urls` and `regularize_numbers`. Replace the SMS text with the results of regularizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c0359c257d3f48a95c181aa6f18b937f",
     "grade": false,
     "grade_id": "cell-baf309d483f7d528",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>sms</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in  _num_  a wkly comp to win FA Cu...</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been  _num_  we...</td>\n",
       "      <td>148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ham</td>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>spam</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile  _num_  months or more? U R en...</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm gonna be home soon and i don't want to tal...</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>spam</td>\n",
       "      <td>SIX chances to win CASH! From  _num_  to  _num...</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>spam</td>\n",
       "      <td>URGENT! You have won a  _num_  week FREE membe...</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>spam</td>\n",
       "      <td>XXXMobileMovieClub: To use your credit, click ...</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ham</td>\n",
       "      <td>Oh k...i'm watching here:)</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ham</td>\n",
       "      <td>Eh u remember how  _num_  spell his name... Ye...</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ham</td>\n",
       "      <td>Fine if thatåÕs the way u feel. ThatåÕs the wa...</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>spam</td>\n",
       "      <td>England v Macedonia - dont miss the goals/team...</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ham</td>\n",
       "      <td>Is that seriously how you spell his name?</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ham</td>\n",
       "      <td>IÛ÷m going to try for  _num_  months ha ha on...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ham</td>\n",
       "      <td>So Ì_ pay first lar... Then when is da stock c...</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ham</td>\n",
       "      <td>Aft i finish my lunch then i go str down lor. ...</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ffffffffff. Alright no way I can meet up with ...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ham</td>\n",
       "      <td>Just forced myself to eat a slice. I'm really ...</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ham</td>\n",
       "      <td>Lol your always so convincing.</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ham</td>\n",
       "      <td>Did you catch the bus ? Are you frying an egg ...</td>\n",
       "      <td>134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm back &amp;amp; we're packing the car now, I'll...</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ahhh. Work. I vaguely remember that! What does...</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5542</th>\n",
       "      <td>ham</td>\n",
       "      <td>Armand says get your ass over to epsilon</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5543</th>\n",
       "      <td>ham</td>\n",
       "      <td>U still havent got urself a jacket ah?</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5544</th>\n",
       "      <td>ham</td>\n",
       "      <td>I'm taking derek &amp;amp; taylor to walmart, if I...</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5545</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hi its in durban are you still on this number</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5546</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ic. There are a lotta childporn cars then.</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5547</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your contract mobile  _num_  Mnths? Latest...</td>\n",
       "      <td>160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5548</th>\n",
       "      <td>ham</td>\n",
       "      <td>No, I was trying it all weekend ;V</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5549</th>\n",
       "      <td>ham</td>\n",
       "      <td>You know, wot people wear. T shirts, jumpers, ...</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5550</th>\n",
       "      <td>ham</td>\n",
       "      <td>Cool, what time you think you can get here?</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wen did you get so spiritual and deep. That's ...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5552</th>\n",
       "      <td>ham</td>\n",
       "      <td>Have a safe trip to Nigeria. Wish you happines...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>ham</td>\n",
       "      <td>Hahaha..use your brain dear</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>ham</td>\n",
       "      <td>Well keep in mind I've only got enough gas for...</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5555</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yeh. Indians was nice. Tho it did kane me off ...</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5556</th>\n",
       "      <td>ham</td>\n",
       "      <td>Yes i have. So that's why u texted. Pshew...mi...</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5557</th>\n",
       "      <td>ham</td>\n",
       "      <td>No. I meant the calculation is the same. That ...</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5558</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5559</th>\n",
       "      <td>ham</td>\n",
       "      <td>if you aren't here in the next  &amp;lt;#&amp;gt;  hou...</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5560</th>\n",
       "      <td>ham</td>\n",
       "      <td>Anything lor. Juz both of us lor.</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5561</th>\n",
       "      <td>ham</td>\n",
       "      <td>Get me out of this dump heap. My mom decided t...</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5562</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lor... Sony ericsson salesman... I ask shuh...</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5563</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ard  _num_  like dat lor.</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5564</th>\n",
       "      <td>ham</td>\n",
       "      <td>Why don't you wait 'til at least wednesday to ...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>ham</td>\n",
       "      <td>Huh y lei...</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>spam</td>\n",
       "      <td>REMINDER FROM O _num_ : To get  _num_ . _num_ ...</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the  _num_ nd time we have tried  _num...</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class                                                sms  length\n",
       "0      ham  Go until jurong point, crazy.. Available only ...     111\n",
       "1      ham                      Ok lar... Joking wif u oni...      29\n",
       "2     spam  Free entry in  _num_  a wkly comp to win FA Cu...     155\n",
       "3      ham  U dun say so early hor... U c already then say...      49\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...      61\n",
       "5     spam  FreeMsg Hey there darling it's been  _num_  we...     148\n",
       "6      ham  Even my brother is not like to speak with me. ...      77\n",
       "7      ham  As per your request 'Melle Melle (Oru Minnamin...     160\n",
       "8     spam  WINNER!! As a valued network customer you have...     158\n",
       "9     spam  Had your mobile  _num_  months or more? U R en...     154\n",
       "10     ham  I'm gonna be home soon and i don't want to tal...     109\n",
       "11    spam  SIX chances to win CASH! From  _num_  to  _num...     136\n",
       "12    spam  URGENT! You have won a  _num_  week FREE membe...     156\n",
       "13     ham  I've been searching for the right words to tha...     196\n",
       "14     ham                I HAVE A DATE ON SUNDAY WITH WILL!!      35\n",
       "15    spam  XXXMobileMovieClub: To use your credit, click ...     149\n",
       "16     ham                         Oh k...i'm watching here:)      26\n",
       "17     ham  Eh u remember how  _num_  spell his name... Ye...      81\n",
       "18     ham  Fine if thatåÕs the way u feel. ThatåÕs the wa...      58\n",
       "19    spam  England v Macedonia - dont miss the goals/team...     156\n",
       "20     ham          Is that seriously how you spell his name?      41\n",
       "21     ham  IÛ÷m going to try for  _num_  months ha ha on...      49\n",
       "22     ham  So Ì_ pay first lar... Then when is da stock c...      53\n",
       "23     ham  Aft i finish my lunch then i go str down lor. ...      88\n",
       "24     ham  Ffffffffff. Alright no way I can meet up with ...      57\n",
       "25     ham  Just forced myself to eat a slice. I'm really ...     144\n",
       "26     ham                     Lol your always so convincing.      30\n",
       "27     ham  Did you catch the bus ? Are you frying an egg ...     134\n",
       "28     ham  I'm back &amp; we're packing the car now, I'll...      75\n",
       "29     ham  Ahhh. Work. I vaguely remember that! What does...      64\n",
       "...    ...                                                ...     ...\n",
       "5542   ham           Armand says get your ass over to epsilon      40\n",
       "5543   ham             U still havent got urself a jacket ah?      38\n",
       "5544   ham  I'm taking derek &amp; taylor to walmart, if I...     154\n",
       "5545   ham      Hi its in durban are you still on this number      45\n",
       "5546   ham         Ic. There are a lotta childporn cars then.      42\n",
       "5547  spam  Had your contract mobile  _num_  Mnths? Latest...     160\n",
       "5548   ham                 No, I was trying it all weekend ;V      34\n",
       "5549   ham  You know, wot people wear. T shirts, jumpers, ...      87\n",
       "5550   ham        Cool, what time you think you can get here?      43\n",
       "5551   ham  Wen did you get so spiritual and deep. That's ...      51\n",
       "5552   ham  Have a safe trip to Nigeria. Wish you happines...      91\n",
       "5553   ham                        Hahaha..use your brain dear      27\n",
       "5554   ham  Well keep in mind I've only got enough gas for...      98\n",
       "5555   ham  Yeh. Indians was nice. Tho it did kane me off ...     153\n",
       "5556   ham  Yes i have. So that's why u texted. Pshew...mi...      63\n",
       "5557   ham  No. I meant the calculation is the same. That ...     273\n",
       "5558   ham                             Sorry, I'll call later      22\n",
       "5559   ham  if you aren't here in the next  &lt;#&gt;  hou...      66\n",
       "5560   ham                  Anything lor. Juz both of us lor.      33\n",
       "5561   ham  Get me out of this dump heap. My mom decided t...      70\n",
       "5562   ham  Ok lor... Sony ericsson salesman... I ask shuh...      96\n",
       "5563   ham                          Ard  _num_  like dat lor.      19\n",
       "5564   ham  Why don't you wait 'til at least wednesday to ...      67\n",
       "5565   ham                                       Huh y lei...      12\n",
       "5566  spam  REMINDER FROM O _num_ : To get  _num_ . _num_ ...     147\n",
       "5567  spam  This is the  _num_ nd time we have tried  _num...     161\n",
       "5568   ham              Will Ì_ b going to esplanade fr home?      37\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...      57\n",
       "5570   ham  The guy did some bitching but I acted like i'd...     125\n",
       "5571   ham                         Rofl. Its true to its name      26\n",
       "\n",
       "[5572 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Regularize/tokenize URLs and numbers\n",
    "from regularize import regularize_urls, regularize_numbers\n",
    "sms_df['sms']  = regularize_urls(sms_df['sms'])\n",
    "sms_df['sms']  = regularize_numbers(sms_df['sms'])\n",
    "sms_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6441ac21abf1d517b734c4485e21c7c9",
     "grade": false,
     "grade_id": "cell-de2e6d1c29eed36c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Step 1.2.2 Results\n",
    "\n",
    "Re-run the CountVectorizer, re-create vector `X`, and re-compute the top 30 spam terms.  Store the top 30 spam terms in `top_spam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d37ac09625d13c349830741fe537e947",
     "grade": false,
     "grade_id": "cell-1e95a42f188d7f93",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_num_         3289\n",
       "free           228\n",
       "txt            165\n",
       "ur             144\n",
       "_url_          141\n",
       "mobile         129\n",
       "stop           126\n",
       "text           125\n",
       "claim          113\n",
       "reply          104\n",
       "prize           92\n",
       "just            78\n",
       "won             76\n",
       "cash            76\n",
       "nokia           71\n",
       "send            70\n",
       "win             70\n",
       "new             69\n",
       "urgent          63\n",
       "week            60\n",
       "tone            59\n",
       "box             57\n",
       "msg             56\n",
       "service         56\n",
       "contact         56\n",
       "guaranteed      50\n",
       "ppm             49\n",
       "customer        49\n",
       "mins            47\n",
       "phone           46\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: Top-30 spam terms\n",
    "top_spam = top_k(sms_df[sms_df['class'] == 'spam'], vec, 30)\n",
    "display(top_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_num_    1227\n",
       "gt        318\n",
       "lt        316\n",
       "just      293\n",
       "ok        287\n",
       "ll        265\n",
       "ur        241\n",
       "know      236\n",
       "good      233\n",
       "got       233\n",
       "like      232\n",
       "come      228\n",
       "day       214\n",
       "time      201\n",
       "love      199\n",
       "going     169\n",
       "home      165\n",
       "want      165\n",
       "lor       162\n",
       "need      158\n",
       "sorry     157\n",
       "don       151\n",
       "da        150\n",
       "today     138\n",
       "later     135\n",
       "dont      132\n",
       "send      129\n",
       "did       129\n",
       "think     128\n",
       "tell      123\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "top_ham = top_k(sms_df[sms_df['class'] == 'ham'], vec, 30)\n",
    "display(top_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "29a9d0b13ff59ced25cfd95d649bd781",
     "grade": true,
     "grade_id": "cell-87d1d4e483d3deeb",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_num_         3289\n",
       "free           228\n",
       "txt            165\n",
       "ur             144\n",
       "_url_          141\n",
       "mobile         129\n",
       "stop           126\n",
       "text           125\n",
       "claim          113\n",
       "reply          104\n",
       "prize           92\n",
       "just            78\n",
       "won             76\n",
       "cash            76\n",
       "nokia           71\n",
       "send            70\n",
       "win             70\n",
       "new             69\n",
       "urgent          63\n",
       "week            60\n",
       "tone            59\n",
       "box             57\n",
       "msg             56\n",
       "service         56\n",
       "contact         56\n",
       "guaranteed      50\n",
       "ppm             49\n",
       "customer        49\n",
       "mins            47\n",
       "phone           46\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(top_spam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "efc75654f41f5036ff0c7c5912477307",
     "grade": true,
     "grade_id": "cell-34f16b95415d9e83",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "if \"_num_\" not in top_spam:\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "f6c98d00928fb3aae439d565ac9b0b59",
     "grade": true,
     "grade_id": "cell-96c2babe756f8ca2",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "if \"_url_\" not in top_spam:\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "3647120b6fe61562fafa75032e99fbef",
     "grade": false,
     "grade_id": "cell-d2694eaa144d8d5b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Step 1.3 Creating Features\n",
    "\n",
    "Currently we have a very large number of features, namely all of the words that aren’t stop words.  Let’s do dimensionality reduction, by only looking for the words that frequently occur in either spam or ham.  Recall that we just recomputed the top-30 spam words.\n",
    "\n",
    "Compute the top-30 ham words, then create a list of “vocabulary” words from the combination of the top spam + ham words.  Create a new feature set called `relevant_vec` using `CountVectorizer` with just the top spam + ham words. \n",
    "\n",
    "Hint: See http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'reaction': 4474,\n",
       " 'dizzamn': 1510,\n",
       " 'easy': 1649,\n",
       " 'delay': 1370,\n",
       " 'seventeen': 4888,\n",
       " 'greatly': 2307,\n",
       " 'narcotics': 3652,\n",
       " 'eva': 1782,\n",
       " 'lotz': 3238,\n",
       " 'payed': 4041,\n",
       " 'atural': 362,\n",
       " 'ruining': 4707,\n",
       " 'mth': 3590,\n",
       " 'edge': 1658,\n",
       " 'meal': 3394,\n",
       " 'solihull': 5125,\n",
       " 'uncles': 5872,\n",
       " 'freek': 2086,\n",
       " 'placed': 4146,\n",
       " 'arent': 276,\n",
       " 'oh': 3844,\n",
       " 'wearing': 6113,\n",
       " 'south': 5173,\n",
       " 'switch': 5466,\n",
       " '_url_': 2,\n",
       " 'mid': 3453,\n",
       " 'onlyfound': 3875,\n",
       " 'whenevr': 6170,\n",
       " 'miiiiiiissssssssss': 3457,\n",
       " 'sachin': 4727,\n",
       " 'hopefully': 2554,\n",
       " 'networking': 3702,\n",
       " 'jumpers': 2912,\n",
       " 'eve': 1785,\n",
       " 'karnan': 2941,\n",
       " 'albi': 138,\n",
       " 'activities': 54,\n",
       " 'men': 3429,\n",
       " 'impatient': 2677,\n",
       " 'face': 1857,\n",
       " 'classmates': 992,\n",
       " 'journey': 2896,\n",
       " 'foot': 2034,\n",
       " 'nattil': 3656,\n",
       " 'definitely': 1362,\n",
       " 'payment': 4044,\n",
       " 'genius': 2191,\n",
       " 'cthen': 1247,\n",
       " 'jaklin': 2828,\n",
       " 'strongly': 5344,\n",
       " 'differences': 1454,\n",
       " 'que': 4410,\n",
       " 'perfume': 4071,\n",
       " 'disclose': 1488,\n",
       " 'darlings': 1313,\n",
       " 'ran': 4449,\n",
       " 'hugs': 2597,\n",
       " 'missionary': 3494,\n",
       " 'strips': 5342,\n",
       " 'monkey': 3540,\n",
       " 'kvb': 3020,\n",
       " 'lonely': 3209,\n",
       " 'hor': 2559,\n",
       " 'files': 1951,\n",
       " 'finding': 1962,\n",
       " 'wats': 6101,\n",
       " 'quote': 4424,\n",
       " 'huiming': 2600,\n",
       " 'whassup': 6164,\n",
       " 'roommates': 4682,\n",
       " 'thasa': 5602,\n",
       " 'attraction': 358,\n",
       " 'search': 4819,\n",
       " 'saturday': 4773,\n",
       " 'questions': 4415,\n",
       " 'miwa': 3506,\n",
       " 'arnt': 294,\n",
       " 'lubly': 3265,\n",
       " 'thy': 5666,\n",
       " 'box': 653,\n",
       " 'careless': 830,\n",
       " 'bsnl': 722,\n",
       " 'reading': 4477,\n",
       " 'angels': 195,\n",
       " 'stress': 5333,\n",
       " 'hopeing': 2555,\n",
       " 'olayiwola': 3859,\n",
       " 'memory': 3428,\n",
       " 'telephonic': 5554,\n",
       " 'ìï': 6407,\n",
       " 'bedrm': 496,\n",
       " 'positions': 4220,\n",
       " 'armand': 289,\n",
       " 'jap': 2836,\n",
       " 'resolved': 4607,\n",
       " 'nuther': 3795,\n",
       " 'copies': 1159,\n",
       " 'mas': 3366,\n",
       " 'nope': 3758,\n",
       " 'hail': 2371,\n",
       " 'evey': 1799,\n",
       " 'salmon': 4746,\n",
       " 'poorly': 4206,\n",
       " 'operate': 3890,\n",
       " 'bpo': 660,\n",
       " 'clearing': 1000,\n",
       " 'decent': 1340,\n",
       " 'monkeys': 3542,\n",
       " 'zindgi': 6396,\n",
       " 'medical': 3407,\n",
       " 'randomly': 4452,\n",
       " 'wn': 6230,\n",
       " 'jeremiah': 2856,\n",
       " 'wt': 6302,\n",
       " 'gut': 2354,\n",
       " 'units': 5899,\n",
       " 'stayin': 5288,\n",
       " 'realize': 4484,\n",
       " 'cloud': 1016,\n",
       " 'relieved': 4550,\n",
       " 'ccna': 863,\n",
       " 'goto': 2277,\n",
       " 'blokes': 600,\n",
       " 'nb': 3664,\n",
       " 'wen': 6145,\n",
       " 'sao': 4758,\n",
       " 'lekdog': 3099,\n",
       " 'milk': 3461,\n",
       " 'oblivious': 3815,\n",
       " 'cookies': 1153,\n",
       " 'hari': 2415,\n",
       " 'fone': 2028,\n",
       " 'movie': 3574,\n",
       " 'ending': 1713,\n",
       " 'hon': 2536,\n",
       " 'floor': 2007,\n",
       " 'dog': 1531,\n",
       " 'details': 1414,\n",
       " 'shitinnit': 4941,\n",
       " 'noooooooo': 3757,\n",
       " 'habba': 2364,\n",
       " 'rearrange': 4490,\n",
       " 'bathing': 465,\n",
       " 'nt': 3781,\n",
       " 'hint': 2501,\n",
       " 'carefully': 829,\n",
       " 'bac': 415,\n",
       " 'placement': 4147,\n",
       " 'govt': 2281,\n",
       " 'praises': 4257,\n",
       " 'suggest': 5393,\n",
       " 'iphone': 2777,\n",
       " 'earth': 1643,\n",
       " 'ruthful': 4720,\n",
       " 'southern': 5174,\n",
       " 'forgive': 2048,\n",
       " 'walking': 6059,\n",
       " 'application': 247,\n",
       " 'fuck': 2122,\n",
       " 'drunken': 1605,\n",
       " 'transfr': 5781,\n",
       " 'lautech': 3068,\n",
       " 'oredi': 3909,\n",
       " 'added': 60,\n",
       " 'adults': 78,\n",
       " 'eyes': 1854,\n",
       " 'computerless': 1093,\n",
       " 'esplanade': 1774,\n",
       " 'dad': 1290,\n",
       " 'gthr': 2332,\n",
       " 'mmmmmm': 3514,\n",
       " 'silence': 5002,\n",
       " 'popcorn': 4209,\n",
       " 'entirely': 1742,\n",
       " 'senses': 4863,\n",
       " 'born': 638,\n",
       " 'meds': 3409,\n",
       " 'msging': 3586,\n",
       " 'needed': 3682,\n",
       " 'worth': 6274,\n",
       " 'wtc': 6303,\n",
       " 'wee': 6125,\n",
       " 'iwas': 2812,\n",
       " 'causing': 859,\n",
       " 'magical': 3312,\n",
       " 'july': 2910,\n",
       " 'appy': 263,\n",
       " 'oyea': 3959,\n",
       " 'paths': 4030,\n",
       " 'squishy': 5249,\n",
       " 'hallaq': 2380,\n",
       " 'loses': 3228,\n",
       " 'cysts': 1285,\n",
       " 'buy': 761,\n",
       " 'postcard': 4230,\n",
       " 'jump': 2911,\n",
       " 'chinatown': 954,\n",
       " 'cause': 857,\n",
       " 'listen': 3166,\n",
       " 'lovable': 3244,\n",
       " 'dodda': 1524,\n",
       " 'yuou': 6388,\n",
       " 'snow': 5110,\n",
       " 'groovying': 2322,\n",
       " 'head': 2439,\n",
       " 'thing': 5625,\n",
       " 'ppl': 4247,\n",
       " 'den': 1380,\n",
       " 'yeesh': 6344,\n",
       " 'burial': 746,\n",
       " 'belt': 524,\n",
       " 'aust': 374,\n",
       " 'babyjontet': 412,\n",
       " 'destination': 1411,\n",
       " 'soul': 5165,\n",
       " 'wating': 6099,\n",
       " 'poortiyagi': 4207,\n",
       " 'ben': 525,\n",
       " 'oscar': 3920,\n",
       " 'outstanding': 3938,\n",
       " 'review': 4636,\n",
       " 'lyk': 3286,\n",
       " 'note': 3770,\n",
       " 'mathe': 3376,\n",
       " 'watched': 6091,\n",
       " 'brainless': 663,\n",
       " 'slightly': 5062,\n",
       " 'instantly': 2741,\n",
       " 'mouth': 3571,\n",
       " 'willing': 6193,\n",
       " 'priority': 4314,\n",
       " 'starts': 5277,\n",
       " 'february': 1914,\n",
       " 'yupz': 6390,\n",
       " 'pathaya': 4029,\n",
       " 'talk': 5502,\n",
       " 'comin': 1062,\n",
       " 'stayed': 5287,\n",
       " 'discussed': 1493,\n",
       " 'declare': 1348,\n",
       " 'citizen': 980,\n",
       " 'texting': 5591,\n",
       " 'lower': 3259,\n",
       " 'footbl': 2036,\n",
       " 'practicum': 4255,\n",
       " 'modules': 3525,\n",
       " 'jan': 2831,\n",
       " 'doinat': 1537,\n",
       " 'howard': 2578,\n",
       " 'admit': 72,\n",
       " 'bring': 694,\n",
       " 'tui': 5827,\n",
       " 'arrive': 301,\n",
       " 'def': 1357,\n",
       " 'hi': 2490,\n",
       " 'ko': 3003,\n",
       " 'actual': 56,\n",
       " 'help': 2473,\n",
       " 'amp': 178,\n",
       " 'gave': 2176,\n",
       " 'panren': 3984,\n",
       " 'riddance': 4644,\n",
       " 'plz': 4180,\n",
       " 'chex': 935,\n",
       " 'hundreds': 2605,\n",
       " 'grumpy': 2330,\n",
       " 'matured': 3384,\n",
       " 'suits': 5398,\n",
       " 'seeking': 4836,\n",
       " 'falling': 1880,\n",
       " 'nike': 3731,\n",
       " 'groovy': 2321,\n",
       " 'eggs': 1676,\n",
       " 'following': 2025,\n",
       " 'uup': 5953,\n",
       " 'data': 1318,\n",
       " 'reacting': 4473,\n",
       " 'tata': 5521,\n",
       " 'mmmmm': 3513,\n",
       " 'breath': 679,\n",
       " 'blanked': 584,\n",
       " 'mint': 3476,\n",
       " 'attracts': 360,\n",
       " 'sun': 5405,\n",
       " 'role': 4673,\n",
       " 'offense': 3830,\n",
       " 'depression': 1396,\n",
       " 'oi': 3845,\n",
       " 'delayed': 1371,\n",
       " 'house': 2574,\n",
       " 'blacko': 579,\n",
       " 'commercial': 1067,\n",
       " 'dorm': 1556,\n",
       " 'sehwag': 4840,\n",
       " 'abel': 11,\n",
       " 'janx': 2835,\n",
       " 'mum': 3604,\n",
       " 'nose': 3767,\n",
       " 'authorise': 375,\n",
       " 'looovvve': 3221,\n",
       " 'killing': 2978,\n",
       " 'account': 39,\n",
       " 'noice': 3747,\n",
       " 'fetch': 1931,\n",
       " 'wildlife': 6192,\n",
       " 'mumtaz': 3609,\n",
       " 'pple': 4248,\n",
       " 'yep': 6351,\n",
       " 'padhe': 3967,\n",
       " 'ashwini': 313,\n",
       " 'silver': 5006,\n",
       " 'guessing': 2344,\n",
       " 'apply': 248,\n",
       " 'notixiquating': 3775,\n",
       " 'sensible': 4864,\n",
       " 'chiong': 959,\n",
       " 'thanks': 5597,\n",
       " 'bars': 451,\n",
       " 'posts': 4234,\n",
       " 'sts': 5347,\n",
       " 'avoiding': 390,\n",
       " 'yelow': 6348,\n",
       " 'saeed': 4732,\n",
       " 'model': 3522,\n",
       " 'hmmm': 2517,\n",
       " 'edison': 1660,\n",
       " 'parantella': 3999,\n",
       " 'talking': 5506,\n",
       " 'dungerees': 1622,\n",
       " 'hardcore': 2411,\n",
       " 'nhite': 3714,\n",
       " 'xxxxxxxx': 6324,\n",
       " 'running': 4715,\n",
       " 'rajini': 4441,\n",
       " 'lambda': 3036,\n",
       " 'jada': 2826,\n",
       " 'remembered': 4559,\n",
       " 'sex': 4889,\n",
       " 'formatting': 2058,\n",
       " 'westonzoyland': 6158,\n",
       " 'valued': 5965,\n",
       " 'ax': 400,\n",
       " 'better': 536,\n",
       " 'maretare': 3353,\n",
       " 'comment': 1066,\n",
       " 'yor': 6364,\n",
       " 'wks': 6227,\n",
       " 'pending': 4059,\n",
       " 'odalebeku': 3825,\n",
       " 'papers': 3991,\n",
       " 'houseful': 2575,\n",
       " 'massive': 3369,\n",
       " 'imma': 2672,\n",
       " 'starshine': 5273,\n",
       " 'madam': 3302,\n",
       " 'wavering': 6103,\n",
       " 'listed': 3165,\n",
       " 'athletic': 341,\n",
       " 'popped': 4210,\n",
       " 'ques': 4412,\n",
       " 'arrived': 302,\n",
       " 'stil': 5309,\n",
       " 'owl': 3954,\n",
       " 'goods': 2265,\n",
       " 'selling': 4849,\n",
       " 'shorts': 4961,\n",
       " 'shrink': 4979,\n",
       " 'howdy': 2580,\n",
       " 'ringing': 4654,\n",
       " 'losing': 3229,\n",
       " 'princes': 4307,\n",
       " 'tallent': 5510,\n",
       " 'whilltake': 6175,\n",
       " 'yan': 6333,\n",
       " 'jaykwon': 2842,\n",
       " 'measure': 3402,\n",
       " 'poet': 4189,\n",
       " 'named': 3643,\n",
       " 'cashed': 846,\n",
       " 'ahhh': 115,\n",
       " 'career': 827,\n",
       " 'tongued': 5732,\n",
       " 'thursday': 5664,\n",
       " 'thesis': 5619,\n",
       " 'snake': 5102,\n",
       " 'reminding': 4566,\n",
       " 'fats': 1901,\n",
       " 'himso': 2500,\n",
       " 'geting': 2201,\n",
       " 'followin': 2024,\n",
       " 'potential': 4236,\n",
       " 'frnds': 2110,\n",
       " 'propose': 4355,\n",
       " 'sized': 5036,\n",
       " 'pocay': 4184,\n",
       " 'gastroenteritis': 2171,\n",
       " 'natwest': 3659,\n",
       " 'joined': 2881,\n",
       " 'escalator': 1768,\n",
       " 'inpersonation': 2731,\n",
       " 'snatch': 5103,\n",
       " 'sitll': 5028,\n",
       " 'chad': 883,\n",
       " 'pink': 4134,\n",
       " 'unconscious': 5875,\n",
       " 'nickey': 3720,\n",
       " 'carlos': 834,\n",
       " 'slices': 5059,\n",
       " 'reserved': 4600,\n",
       " 'creepy': 1225,\n",
       " 'money': 3538,\n",
       " 'prevent': 4297,\n",
       " 'threats': 5650,\n",
       " 'dict': 1438,\n",
       " 'vs': 6034,\n",
       " 'dearly': 1335,\n",
       " 'fixes': 1986,\n",
       " 'executive': 1824,\n",
       " 'june': 2913,\n",
       " 'hello': 2470,\n",
       " 'missunderstding': 3497,\n",
       " 'bold': 618,\n",
       " 'lul': 3271,\n",
       " 'card': 820,\n",
       " 'configure': 1108,\n",
       " 'ias': 2628,\n",
       " 'caroline': 837,\n",
       " 'official': 3836,\n",
       " 'email': 1696,\n",
       " 'closed': 1011,\n",
       " 'springs': 5240,\n",
       " 'rushing': 4719,\n",
       " 'jd': 2846,\n",
       " 'voted': 6031,\n",
       " 'await': 392,\n",
       " 'drunk': 1603,\n",
       " 'tape': 5516,\n",
       " 'ummifying': 5866,\n",
       " 'accent': 28,\n",
       " 'jewelry': 2863,\n",
       " 'seriously': 4875,\n",
       " 'rest': 4617,\n",
       " 'ibn': 2630,\n",
       " 'rvx': 4722,\n",
       " 'londn': 3206,\n",
       " 'reg': 4532,\n",
       " 'distance': 1500,\n",
       " 'crap': 1209,\n",
       " 'safely': 4734,\n",
       " 'key': 2961,\n",
       " 'fulfil': 2132,\n",
       " 'stalking': 5263,\n",
       " 'ese': 1770,\n",
       " 'token': 5717,\n",
       " 'absence': 19,\n",
       " 'ths': 5659,\n",
       " 'swayze': 5451,\n",
       " 'lambu': 3037,\n",
       " 'items': 2801,\n",
       " 'hurried': 2612,\n",
       " 'supports': 5424,\n",
       " 'tessy': 5580,\n",
       " 'church': 976,\n",
       " 'getting': 2205,\n",
       " 'elama': 1686,\n",
       " 'restaurant': 4618,\n",
       " 'yijue': 6359,\n",
       " 'mj': 3507,\n",
       " 'landing': 3040,\n",
       " 'jide': 2868,\n",
       " 'ditto': 1505,\n",
       " 'yest': 6353,\n",
       " 'tho': 5641,\n",
       " 'exeter': 1826,\n",
       " 'dai': 1293,\n",
       " 'just': 2918,\n",
       " 'deal': 1330,\n",
       " 'problum': 4326,\n",
       " 'dogwood': 1535,\n",
       " 'lennon': 3104,\n",
       " 'solved': 5127,\n",
       " 'keypad': 2962,\n",
       " 'greet': 2311,\n",
       " 'goodnight': 2261,\n",
       " 'ethnicity': 1779,\n",
       " 'siguviri': 5001,\n",
       " 'corect': 1162,\n",
       " 'finished': 1968,\n",
       " 'buzy': 765,\n",
       " 'listened': 3167,\n",
       " 'push': 4394,\n",
       " 'long': 3210,\n",
       " 'bell': 516,\n",
       " 'kusruthi': 3019,\n",
       " 'smokes': 5094,\n",
       " 'defo': 1364,\n",
       " 'laughs': 3065,\n",
       " 'leads': 3080,\n",
       " 'cumming': 1262,\n",
       " 'giving': 2226,\n",
       " 'necklace': 3678,\n",
       " 'quit': 4419,\n",
       " 'surya': 5441,\n",
       " 'cutting': 1281,\n",
       " 'inform': 2715,\n",
       " 'paper': 3990,\n",
       " 'single': 5017,\n",
       " 'windows': 6198,\n",
       " 'helens': 2467,\n",
       " 'accenture': 29,\n",
       " 'cres': 1226,\n",
       " 'yen': 6349,\n",
       " 'wheel': 6168,\n",
       " 'yaxx': 6337,\n",
       " 'cab': 773,\n",
       " 'remains': 4556,\n",
       " 'wishes': 6211,\n",
       " 'general': 2188,\n",
       " 'pints': 4135,\n",
       " 'xmas': 6316,\n",
       " 'unusual': 5912,\n",
       " 'hectic': 2461,\n",
       " 'missing': 3493,\n",
       " 'collecting': 1046,\n",
       " 'accumulation': 42,\n",
       " 'drop': 1594,\n",
       " 'dabooks': 1289,\n",
       " 'convincing': 1150,\n",
       " 'life': 3126,\n",
       " 'stoners': 5317,\n",
       " 'neighbour': 3694,\n",
       " 'cross': 1234,\n",
       " 'fidalfication': 1938,\n",
       " 'starting': 5276,\n",
       " 'yr': 6379,\n",
       " 'atleast': 345,\n",
       " 'telphone': 5560,\n",
       " 'havenåõt': 2432,\n",
       " 'pls': 4174,\n",
       " 'gal': 2153,\n",
       " 'deleted': 1373,\n",
       " 'fond': 2026,\n",
       " 'nri': 3780,\n",
       " 'expert': 1840,\n",
       " 'worthless': 6275,\n",
       " 'pleasured': 4170,\n",
       " 'african': 97,\n",
       " 'tryin': 5819,\n",
       " 'water': 6096,\n",
       " 'hes': 2482,\n",
       " 'annoyin': 204,\n",
       " 'rtm': 4698,\n",
       " 'jo': 2871,\n",
       " 'rocks': 4670,\n",
       " 'actin': 51,\n",
       " 'ga': 2148,\n",
       " 'kills': 2979,\n",
       " 'letter': 3114,\n",
       " 'real': 4479,\n",
       " 'bright': 689,\n",
       " 'sony': 5144,\n",
       " 'missy': 3498,\n",
       " 'poem': 4188,\n",
       " 'pert': 4087,\n",
       " 'replying': 4586,\n",
       " 'revealing': 4634,\n",
       " 'affection': 89,\n",
       " 'tues': 5825,\n",
       " 'waste': 6086,\n",
       " 'muchxxlove': 3596,\n",
       " 'tai': 5491,\n",
       " 'apologize': 237,\n",
       " 'sorry': 5156,\n",
       " 'ron': 4678,\n",
       " 'track': 5767,\n",
       " 'tke': 5697,\n",
       " 'gain': 2151,\n",
       " 'lose': 3226,\n",
       " 'aunt': 369,\n",
       " 'swoop': 5468,\n",
       " 'chicken': 940,\n",
       " 'sunny': 5409,\n",
       " 'garments': 2168,\n",
       " 'sportsx': 5233,\n",
       " 'puts': 4397,\n",
       " 'limiting': 3147,\n",
       " 'kidz': 2975,\n",
       " 'lecture': 3090,\n",
       " 'wetherspoons': 6161,\n",
       " 'whereare': 6172,\n",
       " 'bills': 556,\n",
       " 'mums': 3608,\n",
       " 'biatch': 549,\n",
       " 'dry': 1606,\n",
       " 'neshanth': 3697,\n",
       " 'gd': 2181,\n",
       " 'warner': 6079,\n",
       " 'sleepin': 5052,\n",
       " 'doesdiscount': 1527,\n",
       " 'receiving': 4505,\n",
       " 'dump': 1620,\n",
       " 'grand': 2292,\n",
       " 'situation': 5032,\n",
       " 'luvs': 3279,\n",
       " 'yrs': 6380,\n",
       " 'pre': 4270,\n",
       " 'entey': 1740,\n",
       " 'responce': 4611,\n",
       " 'windy': 6200,\n",
       " 'forgets': 2047,\n",
       " 'rinu': 4655,\n",
       " 'rem': 4554,\n",
       " 'iff': 2649,\n",
       " 'siva': 5034,\n",
       " 'kissing': 2990,\n",
       " 'swtheart': 5470,\n",
       " 'resend': 4597,\n",
       " 'habit': 2365,\n",
       " 'lifted': 3132,\n",
       " 'slice': 5058,\n",
       " 'refilled': 4526,\n",
       " 'supposed': 5426,\n",
       " 'grumble': 2329,\n",
       " 'beware': 541,\n",
       " 'costs': 1174,\n",
       " 'jontin': 2892,\n",
       " 'thangam': 5595,\n",
       " 'public': 4373,\n",
       " 'selfindependence': 4845,\n",
       " 'site': 5027,\n",
       " 'bambling': 433,\n",
       " 'portege': 4215,\n",
       " 'clothes': 1015,\n",
       " 'residency': 4603,\n",
       " 'regretted': 4539,\n",
       " 'frankie': 2075,\n",
       " 'gynae': 2361,\n",
       " 'chinnu': 958,\n",
       " 'goin': 2245,\n",
       " 'rhode': 4640,\n",
       " 'distract': 1501,\n",
       " 'survey': 5440,\n",
       " 'oreo': 3910,\n",
       " 'sariyag': 4764,\n",
       " 'batch': 461,\n",
       " 'sef': 4838,\n",
       " 'arng': 292,\n",
       " 'created': 1219,\n",
       " 'dave': 1322,\n",
       " 'happiest': 2406,\n",
       " 'rang': 4453,\n",
       " 'safe': 4733,\n",
       " 'neighbors': 3693,\n",
       " 'spiffing': 5207,\n",
       " 'flea': 1995,\n",
       " 'keys': 2963,\n",
       " 'expecting': 1835,\n",
       " 'loose': 3222,\n",
       " 'bud': 728,\n",
       " 'bao': 440,\n",
       " 'flame': 1990,\n",
       " 'lindsay': 3150,\n",
       " 'ubandu': 5851,\n",
       " 'links': 3157,\n",
       " 'wkend': 6224,\n",
       " 'apo': 234,\n",
       " 'effect': 1671,\n",
       " 'pool': 4203,\n",
       " 'ugo': 5856,\n",
       " 'mia': 3451,\n",
       " 'bettr': 538,\n",
       " 'comfey': 1060,\n",
       " 'lifeis': 3128,\n",
       " 'pc': 4048,\n",
       " 'payoh': 4046,\n",
       " 'underwear': 5884,\n",
       " 'speak': 5188,\n",
       " 'mango': 3344,\n",
       " 'ain': 123,\n",
       " 'train': 5771,\n",
       " 'platt': 4157,\n",
       " 'instead': 2742,\n",
       " 'orc': 3904,\n",
       " 'abi': 12,\n",
       " 'spice': 5206,\n",
       " 'reffering': 4525,\n",
       " 'fellow': 1926,\n",
       " 'hurricanes': 2611,\n",
       " 'leaving': 3088,\n",
       " 'headin': 2441,\n",
       " 'shoulders': 4964,\n",
       " 'kochi': 3004,\n",
       " 'arul': 306,\n",
       " 'deposited': 1394,\n",
       " 'field': 1939,\n",
       " 'sonathaya': 5140,\n",
       " 'caveboy': 861,\n",
       " 'alaipayuthe': 137,\n",
       " 'apartment': 229,\n",
       " 'countinlots': 1186,\n",
       " 'xy': 6326,\n",
       " 'kent': 2955,\n",
       " 'fps': 2071,\n",
       " 'joys': 2898,\n",
       " 'style': 5366,\n",
       " 'stitch': 5311,\n",
       " 'ad': 58,\n",
       " 'ow': 3951,\n",
       " 'nething': 3700,\n",
       " 'lov': 3243,\n",
       " 'taunton': 5525,\n",
       " 'computational': 1091,\n",
       " 'bin': 560,\n",
       " 'ystrday': 6381,\n",
       " 'lo': 3184,\n",
       " 'sunroof': 5411,\n",
       " 'michael': 3452,\n",
       " 'txt': 5845,\n",
       " 'wondarfull': 6243,\n",
       " 'valuable': 5963,\n",
       " 'mark': 3356,\n",
       " 'dawns': 1323,\n",
       " 'funs': 2141,\n",
       " 'doug': 1563,\n",
       " 'cream': 1218,\n",
       " 'hopes': 2556,\n",
       " 'witout': 6220,\n",
       " 'andrews': 193,\n",
       " 'macho': 3297,\n",
       " 'useless': 5941,\n",
       " 'strike': 5340,\n",
       " 'bit': 570,\n",
       " 'kaiez': 2926,\n",
       " 'snuggles': 5114,\n",
       " 'di': 1430,\n",
       " 'yahoo': 6329,\n",
       " 'drum': 1602,\n",
       " 'eldest': 1688,\n",
       " 'dlf': 1513,\n",
       " 'loads': 3186,\n",
       " 'reception': 4507,\n",
       " 'lingo': 3155,\n",
       " 'coccooning': 1028,\n",
       " 'jones': 2891,\n",
       " 'tunji': 5832,\n",
       " 'licks': 3122,\n",
       " 'bugis': 734,\n",
       " 'babies': 410,\n",
       " 'pick': 4116,\n",
       " 'darlin': 1311,\n",
       " 'pilates': 4129,\n",
       " 'blankets': 586,\n",
       " 'thousad': 5646,\n",
       " 'synced': 5476,\n",
       " 'robinson': 4666,\n",
       " 'shocking': 4948,\n",
       " 'flat': 1992,\n",
       " 'mca': 3391,\n",
       " 'entropication': 1744,\n",
       " 'tiz': 5696,\n",
       " 'superb': 5417,\n",
       " 'nauseous': 3661,\n",
       " 'ovulate': 3949,\n",
       " 'remb': 4557,\n",
       " 'experience': 1838,\n",
       " 'organise': 3912,\n",
       " 'gek': 2187,\n",
       " 'sdryb': 4816,\n",
       " 'dreams': 1578,\n",
       " 'swing': 5464,\n",
       " 'cooperative': 1157,\n",
       " 'hmm': 2516,\n",
       " 'sory': 5162,\n",
       " 'taste': 5518,\n",
       " 'howda': 2579,\n",
       " 'bong': 622,\n",
       " 'road': 4662,\n",
       " 'deep': 1353,\n",
       " 'quitting': 4422,\n",
       " 'mist': 3499,\n",
       " 'twice': 5841,\n",
       " 'greeting': 2312,\n",
       " 'gotten': 2279,\n",
       " 'disappeared': 1483,\n",
       " 'brah': 661,\n",
       " 'copy': 1161,\n",
       " 'colours': 1052,\n",
       " 'urgoin': 5930,\n",
       " 'charge': 899,\n",
       " 'kadeem': 2925,\n",
       " 'time': 5680,\n",
       " 'greatness': 2308,\n",
       " 'harish': 2416,\n",
       " 'joking': 2887,\n",
       " 'sorrows': 5155,\n",
       " 'stressfull': 5336,\n",
       " 'connection': 1119,\n",
       " 'sundayish': 5407,\n",
       " 'issues': 2799,\n",
       " 'spare': 5184,\n",
       " 'db': 1327,\n",
       " 'teach': 5535,\n",
       " 'nights': 3728,\n",
       " 'voila': 6025,\n",
       " 'cherish': 932,\n",
       " 'coin': 1037,\n",
       " 'fishhead': 1979,\n",
       " 'sells': 4850,\n",
       " 'unnecessarily': 5908,\n",
       " 'dictionary': 1439,\n",
       " 'murdered': 3613,\n",
       " 'clearly': 1001,\n",
       " 'matric': 3381,\n",
       " 'swiss': 5465,\n",
       " 'edukkukayee': 1665,\n",
       " 'sane': 4755,\n",
       " 'ummma': 5867,\n",
       " 'imin': 2671,\n",
       " 'pix': 4141,\n",
       " 'alright': 159,\n",
       " 'jackson': 2824,\n",
       " 'room': 4679,\n",
       " 'sit': 5026,\n",
       " 'applying': 250,\n",
       " 'mack': 3298,\n",
       " 'dudes': 1615,\n",
       " 'cappuccino': 815,\n",
       " 'likeyour': 3142,\n",
       " 'wishlist': 6214,\n",
       " 'heal': 2445,\n",
       " 'onion': 3872,\n",
       " 'royal': 4694,\n",
       " 'verified': 5986,\n",
       " 'zeros': 6394,\n",
       " 'casing': 847,\n",
       " 'wasn': 6083,\n",
       " 'period': 4073,\n",
       " 'dled': 1512,\n",
       " 'pax': 4037,\n",
       " 'justify': 2921,\n",
       " 'psychiatrist': 4368,\n",
       " 'warm': 6076,\n",
       " 'waxsto': 6105,\n",
       " 'perpetual': 4078,\n",
       " 'surrounded': 5439,\n",
       " 'syrup': 5478,\n",
       " 'tops': 5745,\n",
       " 'naal': 3633,\n",
       " 'walls': 6063,\n",
       " 'cuddling': 1257,\n",
       " 'unconvinced': 5877,\n",
       " 'grooved': 2320,\n",
       " 'pouts': 4243,\n",
       " 'horse': 2561,\n",
       " 'ans': 207,\n",
       " 'weight': 6134,\n",
       " 'surf': 5431,\n",
       " 'showing': 4974,\n",
       " 'offers': 3833,\n",
       " 'confuses': 1114,\n",
       " 'fujitsu': 2130,\n",
       " 'cake': 778,\n",
       " 'girlie': 2220,\n",
       " 'negative': 3689,\n",
       " 'celebration': 869,\n",
       " 'lab': 3023,\n",
       " 'butting': 759,\n",
       " 'dimension': 1464,\n",
       " 'cave': 860,\n",
       " 'armenia': 290,\n",
       " 'seconds': 4826,\n",
       " 'overa': 3942,\n",
       " 'asking': 319,\n",
       " 'iraq': 2779,\n",
       " 'wa': 6036,\n",
       " 'breaking': 678,\n",
       " 'mcr': 3393,\n",
       " 'guidance': 2345,\n",
       " 'bags': 421,\n",
       " 'resume': 4625,\n",
       " 'concert': 1100,\n",
       " 'cya': 1283,\n",
       " 'log': 3197,\n",
       " 'bookedthe': 627,\n",
       " 'wotu': 6278,\n",
       " 'decades': 1339,\n",
       " 'fourth': 2067,\n",
       " 'plate': 4156,\n",
       " 'katexxx': 2944,\n",
       " 'cartons': 842,\n",
       " 'jazz': 2844,\n",
       " 'ha': 2363,\n",
       " 'ml': 3508,\n",
       " 'eshxxxxxxxxxxx': 1771,\n",
       " 'ham': 2381,\n",
       " 'telly': 5559,\n",
       " 'break': 675,\n",
       " 'ternal': 5573,\n",
       " 'lodging': 3196,\n",
       " 'yay': 6339,\n",
       " 'ramen': 4448,\n",
       " 'liver': 3178,\n",
       " 'shame': 4903,\n",
       " 'hee': 2462,\n",
       " 'predictive': 4275,\n",
       " 'apeshit': 231,\n",
       " 'league': 3082,\n",
       " 'cupboard': 1264,\n",
       " 'shb': 4915,\n",
       " 'borderline': 634,\n",
       " 'died': 1447,\n",
       " 'dock': 1518,\n",
       " 'approaches': 255,\n",
       " 'oooooh': 3881,\n",
       " 'sporadically': 5230,\n",
       " 'invoices': 2769,\n",
       " 'heehee': 2463,\n",
       " 'tendencies': 5566,\n",
       " 'kaypoh': 2947,\n",
       " 'tm': 5699,\n",
       " 'claypot': 993,\n",
       " 'ralphs': 4446,\n",
       " 'retard': 4627,\n",
       " 'diapers': 1435,\n",
       " 'xxxxxxxxxxxxxx': 6325,\n",
       " 'styles': 5367,\n",
       " 'prescribed': 4284,\n",
       " 'god': 2240,\n",
       " 'stand': 5265,\n",
       " 'nig': 3722,\n",
       " 'othrwise': 3923,\n",
       " 'cards': 823,\n",
       " 'starve': 5278,\n",
       " 'persons': 4085,\n",
       " 'pizza': 4143,\n",
       " 'takes': 5497,\n",
       " 'struggling': 5346,\n",
       " 'simply': 5010,\n",
       " 'woah': 6234,\n",
       " 'darren': 1314,\n",
       " 'ideas': 2643,\n",
       " 'pale': 3977,\n",
       " 'swhrt': 5461,\n",
       " 'taken': 5496,\n",
       " 'durban': 1625,\n",
       " 'sup': 5415,\n",
       " 'dobby': 1516,\n",
       " 'kicchu': 2968,\n",
       " 'arngd': 293,\n",
       " 'likely': 3140,\n",
       " 'woozles': 6254,\n",
       " 'hair': 2372,\n",
       " 'frnt': 2115,\n",
       " 'requires': 4595,\n",
       " 'neglet': 3691,\n",
       " 'hangin': 2393,\n",
       " 'understand': 5881,\n",
       " 'recently': 4506,\n",
       " 'andres': 192,\n",
       " 'dull': 1618,\n",
       " 'engagement': 1722,\n",
       " 'ridden': 4645,\n",
       " 'ahmad': 117,\n",
       " 'shd': 4916,\n",
       " 'neck': 3677,\n",
       " 'boss': 640,\n",
       " 'splleing': 5220,\n",
       " 'watch': 6090,\n",
       " 'coping': 1160,\n",
       " 'chip': 960,\n",
       " 'poo': 4200,\n",
       " 'simple': 5008,\n",
       " 'female': 1928,\n",
       " 'fools': 2033,\n",
       " 'lengths': 3103,\n",
       " 'enjoy': 1727,\n",
       " 'onum': 3876,\n",
       " 'felt': 1927,\n",
       " 'ors': 3916,\n",
       " 'freedom': 2085,\n",
       " 'caught': 856,\n",
       " 'appt': 262,\n",
       " 'purity': 4391,\n",
       " 'brainy': 665,\n",
       " 'talkin': 5505,\n",
       " 'forwarded': 2065,\n",
       " 'apart': 228,\n",
       " 'cleaning': 996,\n",
       " 'nav': 3662,\n",
       " 'sooo': 5149,\n",
       " 'challenging': 886,\n",
       " 'culdnt': 1259,\n",
       " 'rudi': 4704,\n",
       " 'mate': 3373,\n",
       " 'shopping': 4954,\n",
       " 'eatin': 1652,\n",
       " 'craziest': 1215,\n",
       " 'buddy': 729,\n",
       " 'cuppa': 1265,\n",
       " 'center': 873,\n",
       " ...}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top_ham1 = top_ham.to_frame()\n",
    "top_spam1 = top_spam.to_frame()\n",
    "merge = pd.concat([top_ham1, top_spam1])\n",
    "\n",
    "merge = merge.reset_index().rename(columns = {'index':'name'})[['name']]\n",
    "merge = merge.drop_duplicates()\n",
    "merge = merge.reset_index()[['name']]\n",
    "merge = merge.reset_index()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_num_': 0,\n",
       " '_url_': 32,\n",
       " 'box': 47,\n",
       " 'cash': 40,\n",
       " 'claim': 36,\n",
       " 'come': 11,\n",
       " 'contact': 50,\n",
       " 'customer': 53,\n",
       " 'da': 22,\n",
       " 'day': 12,\n",
       " 'did': 27,\n",
       " 'don': 21,\n",
       " 'dont': 25,\n",
       " 'free': 30,\n",
       " 'going': 15,\n",
       " 'good': 8,\n",
       " 'got': 9,\n",
       " 'gt': 1,\n",
       " 'guaranteed': 51,\n",
       " 'home': 16,\n",
       " 'just': 3,\n",
       " 'know': 7,\n",
       " 'later': 24,\n",
       " 'like': 10,\n",
       " 'll': 5,\n",
       " 'lor': 18,\n",
       " 'love': 14,\n",
       " 'lt': 2,\n",
       " 'mins': 54,\n",
       " 'mobile': 33,\n",
       " 'msg': 48,\n",
       " 'need': 19,\n",
       " 'new': 43,\n",
       " 'nokia': 41,\n",
       " 'ok': 4,\n",
       " 'phone': 55,\n",
       " 'ppm': 52,\n",
       " 'prize': 38,\n",
       " 'reply': 37,\n",
       " 'send': 26,\n",
       " 'service': 49,\n",
       " 'sorry': 20,\n",
       " 'stop': 34,\n",
       " 'tell': 29,\n",
       " 'text': 35,\n",
       " 'think': 28,\n",
       " 'time': 13,\n",
       " 'today': 23,\n",
       " 'tone': 46,\n",
       " 'txt': 31,\n",
       " 'ur': 6,\n",
       " 'urgent': 44,\n",
       " 'want': 17,\n",
       " 'week': 45,\n",
       " 'win': 42,\n",
       " 'won': 39}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = dict(zip(merge.name, merge.index))\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "309dcbcd7d879c60de3b7b3efae3464b",
     "grade": false,
     "grade_id": "cell-dbbcb0962c7f8319",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# TODO: Vector of 'important' words\n",
    "\n",
    "relevant_vec = CountVectorizer(decode_error = 'ignore', vocabulary = mapping, stop_words = 'english')\n",
    "relevant_vec.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2affbe17f29fd645f788dd5e0976dc91",
     "grade": false,
     "grade_id": "cell-1589584e83deab0c",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "This cell adds an sms length feature (normalized by the maximum length) and creates training and test sets for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection as ms\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import numpy as np\n",
    "\n",
    "# X is the feature array, based off relevant words\n",
    "X = relevant_vec.fit_transform(sms_df['sms'].values).toarray()\n",
    "\n",
    "# Compute the length of each sms message, normalized by max length\n",
    "Xlen = np.zeros((X.shape[0],1))\n",
    "inx = 0\n",
    "for v in sms_df['sms'].values:\n",
    "        Xlen[inx,0] = len(v)\n",
    "        inx += 1\n",
    "Xlen = Xlen / max(Xlen)\n",
    "# Add the length as another feature\n",
    "X = np.hstack((X, Xlen))\n",
    "\n",
    "#y = sms_df['class'].values\n",
    "y = np.array((sms_df['class'] == 'spam').astype(int))\n",
    "\n",
    "# Now we split...\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.2, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d42ce5658f0991324503064f13023d15",
     "grade": false,
     "grade_id": "cell-f1fe67f85011eb09",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Step 1.4 Classifier Evaluation\n",
    "\n",
    "Write a function `spam_classify(model)` that takes a constructed model as input, `fit`s the model on the training set, `predict`s on the test set, and returns the `score` on the test outputs. The monospaced words are hints for which functions you should use. Note that you may need to run the cell below again as your write the constructor calls so that you do not get duplicates in your results table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_predict, y_actual):\n",
    "    cnt = 0\n",
    "    for i in range(len(y_predict)):\n",
    "        y_p = y_predict[i]\n",
    "        y_a = y_actual[i]\n",
    "        if y_p == y_a:\n",
    "            cnt += 1\n",
    "    return cnt/len(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "7bea0f97cf06069700ec841cdb90e635",
     "grade": false,
     "grade_id": "cell-5ac2dcfcdeb189d5",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Write your spam_classify function here.\n",
    "\n",
    "def spam_classify(model):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return get_accuracy(y_pred, y_test) \n",
    "\n",
    "# Results, as a list of dictionaries\n",
    "classifier_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "23e72cf8138e7f896e8288e75baec707",
     "grade": false,
     "grade_id": "cell-079169cb63555638",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Step 1.4.1 Decision Trees\n",
    "\n",
    "Construct 6 Decision Trees **with random state 42**. Use maximum depths of 1, 2, 3, 4, 5, and the default. Store them in variables `dt1` to `dt6`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "b27a2c9764fa94bc56b7945bb89a3f50",
     "grade": false,
     "grade_id": "cell-b8655ff4ca0dd4a0",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "import sklearn.model_selection as ms\n",
    "\n",
    "# TODO: Construct your 5 decision trees here.\n",
    "dt1 = tree.DecisionTreeClassifier(max_depth=1,criterion='entropy', random_state=42)\n",
    "dt2 = tree.DecisionTreeClassifier(max_depth=2,criterion='entropy', random_state=42)\n",
    "dt3 = tree.DecisionTreeClassifier(max_depth=3,criterion='entropy', random_state=42)\n",
    "dt4 = tree.DecisionTreeClassifier(max_depth=4,criterion='entropy', random_state=42)\n",
    "dt5 = tree.DecisionTreeClassifier(max_depth=5,criterion='entropy', random_state=42)\n",
    "dt6 = tree.DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "\n",
    "classifier_results.append({'Classifier': 'DecTree', 'Param': 'Depth=1', 'Score': spam_classify(dt1)})\n",
    "classifier_results.append({'Classifier': 'DecTree', 'Param': 'Depth=2', 'Score': spam_classify(dt2)})\n",
    "classifier_results.append({'Classifier': 'DecTree', 'Param': 'Depth=3', 'Score': spam_classify(dt3)})\n",
    "classifier_results.append({'Classifier': 'DecTree', 'Param': 'Depth=4', 'Score': spam_classify(dt4)})\n",
    "classifier_results.append({'Classifier': 'DecTree', 'Param': 'Depth=5', 'Score': spam_classify(dt5)})\n",
    "classifier_results.append({'Classifier': 'DecTree', 'Param': '', 'Score': spam_classify(dt6)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Classifier': 'DecTree', 'Param': 'Depth=1', 'Score': 0.9399103139013453},\n",
       " {'Classifier': 'DecTree', 'Param': 'Depth=2', 'Score': 0.9399103139013453},\n",
       " {'Classifier': 'DecTree', 'Param': 'Depth=3', 'Score': 0.9497757847533632},\n",
       " {'Classifier': 'DecTree', 'Param': 'Depth=4', 'Score': 0.9560538116591928},\n",
       " {'Classifier': 'DecTree', 'Param': 'Depth=5', 'Score': 0.9587443946188341},\n",
       " {'Classifier': 'DecTree', 'Param': '', 'Score': 0.9713004484304932}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2df0e43629d8293427bdd2ee592cd873",
     "grade": false,
     "grade_id": "cell-ec596081d9cf14eb",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Step 1.4.2 Logistic Regression\n",
    "\n",
    "Construct 2 `liblinear` Logistic Regression classifiers **with random state 42**. Use `l1` and `l2` regularization penalties. Store them in variables `lr1` and `lr2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "528e701cbb5c6e05a7e25c4fb61cf2d2",
     "grade": false,
     "grade_id": "cell-6d614d5da21ab01a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# TODO: Construct your 2 logistic regression classifiers here.\n",
    "lr1 = LogisticRegression(penalty='l1',random_state=42)\n",
    "lr2 = LogisticRegression(penalty='l2',random_state=42)\n",
    "classifier_results.append({'Classifier': 'LogReg',  'Param': 'Reg=l1',  'Score': spam_classify(lr1)})\n",
    "classifier_results.append({'Classifier': 'LogReg',  'Param': 'Reg=l2',  'Score': spam_classify(lr2)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Classifier': 'DecTree', 'Param': 'Depth=1', 'Score': 0.9399103139013453},\n",
       " {'Classifier': 'DecTree', 'Param': 'Depth=2', 'Score': 0.9399103139013453},\n",
       " {'Classifier': 'DecTree', 'Param': 'Depth=3', 'Score': 0.9497757847533632},\n",
       " {'Classifier': 'DecTree', 'Param': 'Depth=4', 'Score': 0.9560538116591928},\n",
       " {'Classifier': 'DecTree', 'Param': 'Depth=5', 'Score': 0.9587443946188341},\n",
       " {'Classifier': 'DecTree', 'Param': '', 'Score': 0.9713004484304932},\n",
       " {'Classifier': 'LogReg', 'Param': 'Reg=l1', 'Score': 0.9713004484304932},\n",
       " {'Classifier': 'LogReg', 'Param': 'Reg=l2', 'Score': 0.9704035874439462}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1.4.3 Support Vector Machines\n",
    "\n",
    "Construct 1 Support Vector Machines classifier with the kernel coefficient set by `gamma=\"auto\"` and **with random state 42**. Ensure the model computes probabilities for the 2 classes by setting the probability flag to True. Store the model in the variable `svm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "d6324df97874a74e398b2157b87ee77f",
     "grade": false,
     "grade_id": "cell-7a47089ef900f7cf",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# TODO: Construct your 1 support vector machines classifier here.\n",
    "svm = SVC(random_state = 42,probability=True, gamma = 'auto')\n",
    "\n",
    "classifier_results.append({'Classifier': 'SVM', 'Param': '', 'Score': spam_classify(svm)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d95551eb6cb630047baf39dff6280cfd",
     "grade": true,
     "grade_id": "cell-bd5a7c6fca1981db",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Param</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecTree</td>\n",
       "      <td>Depth=1</td>\n",
       "      <td>0.939910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DecTree</td>\n",
       "      <td>Depth=2</td>\n",
       "      <td>0.939910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DecTree</td>\n",
       "      <td>Depth=3</td>\n",
       "      <td>0.949776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecTree</td>\n",
       "      <td>Depth=4</td>\n",
       "      <td>0.956054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DecTree</td>\n",
       "      <td>Depth=5</td>\n",
       "      <td>0.958744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecTree</td>\n",
       "      <td></td>\n",
       "      <td>0.971300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>Reg=l1</td>\n",
       "      <td>0.971300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>Reg=l2</td>\n",
       "      <td>0.970404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM</td>\n",
       "      <td></td>\n",
       "      <td>0.971300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier    Param     Score\n",
       "0    DecTree  Depth=1  0.939910\n",
       "1    DecTree  Depth=2  0.939910\n",
       "2    DecTree  Depth=3  0.949776\n",
       "3    DecTree  Depth=4  0.956054\n",
       "4    DecTree  Depth=5  0.958744\n",
       "5    DecTree           0.971300\n",
       "6     LogReg   Reg=l1  0.971300\n",
       "7     LogReg   Reg=l2  0.970404\n",
       "8        SVM           0.971300"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(classifier_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "c08cda5b5ef2e84fe5a8a83d5be3f252",
     "grade": true,
     "grade_id": "cell-e2c9c282f7fa5cf9",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Don't delete this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "fc3d68bd8df5ab32ffe19d4313a86a70",
     "grade": true,
     "grade_id": "cell-bc1d34ca8a81688f",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Don't delete this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7fe08a3313d089214cbf0f40b01446fa",
     "grade": true,
     "grade_id": "cell-1fb46cb125d837ec",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Don't delete this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "35b14cff18645eac72474542a9a16a48",
     "grade": false,
     "grade_id": "cell-6a03910a38cee794",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Step 2.0 Ensembles\n",
    "\n",
    "We are going to use your `spam_classify` function again. No changes needed. Note that you may need to run the cell below again as your write the constructor calls so that you do not get duplicates in your results table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results, as a list of dictionaries\n",
    "classifier_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "18ffa3d52d688456eade3febd6216032",
     "grade": false,
     "grade_id": "cell-15879b506677ef12",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Step 2.1 Random Forest\n",
    "\n",
    "Construct 1 random forest classifier with 31 estimators and **random state 314**. Store it in the variable `rfor`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c775a91b211b942fa67a9323d70681da",
     "grade": false,
     "grade_id": "cell-8904044fe51b7d93",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# TODO: Construct your random forest classifier here.\n",
    "rfor = RandomForestClassifier(random_state = 314, n_estimators = 31)\n",
    "\n",
    "classifier_results.append({'Classifier': 'RFo', 'Param': 'Count=31', 'Score': spam_classify(rfor)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Classifier': 'RFo', 'Param': 'Count=31', 'Score': 0.9829596412556054}]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5c4801dfbe43b93d3b9915733d550818",
     "grade": false,
     "grade_id": "cell-7180eb695e1adc60",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Step 2.2 Bagging\n",
    "\n",
    "Construct 4 bagging classifiers with 31 estimators and **random state 314**. The base classifiers should be `dt6`, `lr1`, `lr2`, and `svm`. Store them in variables `bag1` to `bag4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "16631f005c32c357987b989abafe0992",
     "grade": false,
     "grade_id": "cell-b0686d3d23f1fed2",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "# TODO: Construct your bagging classifier here.\n",
    "bag1 = BaggingClassifier(base_estimator=dt6,n_estimators=31, random_state=314)\n",
    "bag2 = BaggingClassifier(base_estimator=lr1,n_estimators=31, random_state=314)\n",
    "bag3 = BaggingClassifier(base_estimator=lr2,n_estimators=31, random_state=314)\n",
    "bag4 = BaggingClassifier(base_estimator=svm,n_estimators=31, random_state=314)\n",
    "classifier_results.append({'Classifier': 'Bag', 'Param': 'Base=dt6', 'Score': spam_classify(bag1)})\n",
    "classifier_results.append({'Classifier': 'Bag', 'Param': 'Base=lr1', 'Score': spam_classify(bag2)})\n",
    "classifier_results.append({'Classifier': 'Bag', 'Param': 'Base=lr2', 'Score': spam_classify(bag3)})\n",
    "classifier_results.append({'Classifier': 'Bag', 'Param': 'Base=svm', 'Score': spam_classify(bag4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Classifier': 'RFo', 'Param': 'Count=31', 'Score': 0.9829596412556054},\n",
       " {'Classifier': 'Bag', 'Param': 'Base=dt6', 'Score': 0.9820627802690582},\n",
       " {'Classifier': 'Bag', 'Param': 'Base=lr1', 'Score': 0.9739910313901345},\n",
       " {'Classifier': 'Bag', 'Param': 'Base=lr2', 'Score': 0.9713004484304932},\n",
       " {'Classifier': 'Bag', 'Param': 'Base=svm', 'Score': 0.9730941704035875}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "af7dba16772b17b0939b064b07c3a29c",
     "grade": false,
     "grade_id": "cell-40dcf747ef974ac4",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Step 2.3 AdaBoost\n",
    "\n",
    "Construct 4 AdaBoost classifiers with 31 estimators and **random state 314**. The base classifiers should be `dt6`, `lr1`, `lr2`, and `svm`. Store them in variables `ada1` to `ada4`. Training these models could take a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "ea9472682aab77ebe333101c267a6b2f",
     "grade": false,
     "grade_id": "cell-98407ded4afef9ac",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-4ef4efe145dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mclassifier_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Classifier'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Ada'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Param'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Base=lr1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mspam_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mada2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mclassifier_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Classifier'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Ada'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Param'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Base=lr2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mspam_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mada3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mclassifier_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Classifier'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Ada'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Param'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'Base=svm'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Score'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mspam_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mada4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-24-6260f4aa9f46>\u001b[0m in \u001b[0;36mspam_classify\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mspam_classify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 random_state)\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# Early termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \"\"\"\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/sklearn/svm/base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    269\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# TODO: Construct your AdaBoost Classifier here.\n",
    "ada1 = AdaBoostClassifier(base_estimator=dt6,n_estimators=31, random_state=314)\n",
    "ada2 = AdaBoostClassifier(base_estimator=lr1,n_estimators=31, random_state=314)\n",
    "ada3 = AdaBoostClassifier(base_estimator=lr2,n_estimators=31, random_state=314)\n",
    "ada4 = AdaBoostClassifier(base_estimator=svm,n_estimators=31, random_state=314)\n",
    "\n",
    "classifier_results.append({'Classifier': 'Ada', 'Param': 'Base=dt6', 'Score': spam_classify(ada1)})\n",
    "classifier_results.append({'Classifier': 'Ada', 'Param': 'Base=lr1', 'Score': spam_classify(ada2)})\n",
    "classifier_results.append({'Classifier': 'Ada', 'Param': 'Base=lr2', 'Score': spam_classify(ada3)})\n",
    "classifier_results.append({'Classifier': 'Ada', 'Param': 'Base=svm', 'Score': spam_classify(ada4)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0ca6a9a4f1934e3c00da4a4d5ea3566b",
     "grade": true,
     "grade_id": "cell-0f66dd807ebd1208",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Param</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RFo</td>\n",
       "      <td>Count=31</td>\n",
       "      <td>0.982960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bag</td>\n",
       "      <td>Base=dt6</td>\n",
       "      <td>0.982063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bag</td>\n",
       "      <td>Base=lr1</td>\n",
       "      <td>0.973991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bag</td>\n",
       "      <td>Base=lr2</td>\n",
       "      <td>0.971300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bag</td>\n",
       "      <td>Base=svm</td>\n",
       "      <td>0.973094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ada</td>\n",
       "      <td>Base=dt6</td>\n",
       "      <td>0.970404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ada</td>\n",
       "      <td>Base=lr1</td>\n",
       "      <td>0.865471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ada</td>\n",
       "      <td>Base=lr2</td>\n",
       "      <td>0.950673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier     Param     Score\n",
       "0        RFo  Count=31  0.982960\n",
       "1        Bag  Base=dt6  0.982063\n",
       "2        Bag  Base=lr1  0.973991\n",
       "3        Bag  Base=lr2  0.971300\n",
       "4        Bag  Base=svm  0.973094\n",
       "5        Ada  Base=dt6  0.970404\n",
       "6        Ada  Base=lr1  0.865471\n",
       "7        Ada  Base=lr2  0.950673"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(classifier_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "4eb81001a81ba635f562f667264c0779",
     "grade": true,
     "grade_id": "cell-73c7cdd4afcf13c1",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "if min(pd.DataFrame(classifier_results)[\"Score\"][0:5]) < 0.95:\n",
    "    raise ValueError(\"Something went wrong.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "9f724c4eb59627da3ea6beae4a3e0948",
     "grade": true,
     "grade_id": "cell-0779bdf3d1e358bf",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Don't delete this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "60e13717baf10efb002cb5ab834a2eec",
     "grade": false,
     "grade_id": "cell-fe38448acd9d637a",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Step 3.0 Neural Networks\n",
    "\n",
    "Let’s continue building upon our spam classifier, this time using neural networks -- both Perceptrons and feed-forward networks. We are going to use your `spam_classify` function again. No changes needed. Note that you may need to run the cell below again as your write the constructor calls so that you do not get duplicates in your results table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results, as a list of dictionaries\n",
    "classifier_results = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "e20bb829c2adfedcc9212d52506330ec",
     "grade": false,
     "grade_id": "cell-c5eb700301827564",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Step 3.1 Perceptron\n",
    "\n",
    "Construct 1 perception classifier with a maximum number of iterations of 1000, a tolerance of 1e-3, and **random state 42**. Store it in the variable `perc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "91a6771cf346089860f2630f61fc3cf0",
     "grade": false,
     "grade_id": "cell-41da333ff0d0a295",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# TODO: Construct your perception classifier here.\n",
    "perc = Perceptron(max_iter=1000, tol=1e-3, random_state=42)\n",
    "\n",
    "classifier_results.append({'Classifier': 'Perceptron', 'Param': '', 'Score': spam_classify(perc)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "0f2981d6c71d32ee2161267f6f83b7fc",
     "grade": false,
     "grade_id": "cell-6823dd32c72147f1",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Step 3.2 Multi-layer Perceptrons\n",
    "\n",
    "### Step 3.2.1 Small Network\n",
    "\n",
    "Construct 1 MLP classifier with 3 hidden nodes in 1 layer and **random state 42**. Store it in the variable `mlp1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "748e57edf9f3f29474d3a46532509662",
     "grade": false,
     "grade_id": "cell-55f0401c50755dcc",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# TODO: Construct your small MLP classifier here.\n",
    "mlp1 = MLPClassifier(hidden_layer_sizes=(3,),random_state=42)\n",
    "\n",
    "classifier_results.append({'Classifier': 'NN', 'Param': 'Hidden=(3)', 'Score': spam_classify(mlp1)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "217938ad932097b90d2a2bda7844e927",
     "grade": false,
     "grade_id": "cell-e30f9c7bf820a2a6",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Step 3.2.2 Medium Network\n",
    "\n",
    "Construct 1 MLP classifier with 10 hidden nodes in 1 layer and **random state 42**. Store it in the variable `mlp2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5484423906435031d617a371c550e7e0",
     "grade": false,
     "grade_id": "cell-60736d35c84619a6",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Construct your medium MLP classifier here.\n",
    "# YOUR CODE HERE\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=(10,),random_state=42)\n",
    "\n",
    "classifier_results.append({'Classifier': 'NN', 'Param': 'Hidden=(10)', 'Score': spam_classify(mlp2)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "357f0696bee01a0b9715513b10156b40",
     "grade": false,
     "grade_id": "cell-6ca2134fa5584d4f",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Step 3.2.3 Large Network\n",
    "\n",
    "Construct 1 MLP classifier with 10 hidden nodes in each of 3 layers and **random state 1**. Store it in the variable `mlp3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "eb9eb11a11ef53d481de156cf7bf5d87",
     "grade": false,
     "grade_id": "cell-5c9f4de87cce7e71",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/neural_network/multilayer_perceptron.py:562: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# TODO: Construct your large MLP classifier here.\n",
    "# YOUR CODE HERE\n",
    "mlp3 = MLPClassifier(hidden_layer_sizes=(10,10,10),random_state=1)\n",
    "\n",
    "\n",
    "classifier_results.append({'Classifier': 'NN', 'Param': 'Hidden=(10,10,10)', 'Score': spam_classify(mlp3)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "873e410481e9385ba867ab59faa606b3",
     "grade": true,
     "grade_id": "cell-9b6da5c4d6ff2476",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Param</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td></td>\n",
       "      <td>0.973094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NN</td>\n",
       "      <td>Hidden=(3)</td>\n",
       "      <td>0.976682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NN</td>\n",
       "      <td>Hidden=(10)</td>\n",
       "      <td>0.974888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NN</td>\n",
       "      <td>Hidden=(10,10,10)</td>\n",
       "      <td>0.973094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Classifier              Param     Score\n",
       "0  Perceptron                     0.973094\n",
       "1          NN         Hidden=(3)  0.976682\n",
       "2          NN        Hidden=(10)  0.974888\n",
       "3          NN  Hidden=(10,10,10)  0.973094"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(classifier_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "b1861bba2545d6325b26aaf944a9d3f8",
     "grade": true,
     "grade_id": "cell-5b9c1f9a364535c0",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Don't delete this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "7860ca86e155a8c7a3f1d4ff4a0e985c",
     "grade": true,
     "grade_id": "cell-8a72123a4fe3aa70",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Don't delete this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "127a3f674c9ae6bc62ef69afbeaceb05",
     "grade": true,
     "grade_id": "cell-4207309a28a45272",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Don't delete this cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "82a6c9932351695ba263acc1063d473d",
     "grade": false,
     "grade_id": "cell-40127bfb5b40fa99",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "# Tensorflow\n",
    "\n",
    "## Step 4.1. Loading Data\n",
    "\n",
    "The first cell imports TensorFlow. For this part of the homework, you will use `X_train` and `y_train` created in Step 1.3.\n",
    "\n",
    "Define TensorFlow **columns** (features) for each of the words in the vocabulary from Step 1.3.  Also add an additional column for the length. Store these columns in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "c5b7d1d262704ddc9612feb39d4ed185",
     "grade": false,
     "grade_id": "cell-7f970b016f3c2300",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_num_',\n",
       " 'gt',\n",
       " 'lt',\n",
       " 'just',\n",
       " 'ok',\n",
       " 'll',\n",
       " 'ur',\n",
       " 'know',\n",
       " 'good',\n",
       " 'got',\n",
       " 'like',\n",
       " 'come',\n",
       " 'day',\n",
       " 'time',\n",
       " 'love',\n",
       " 'going',\n",
       " 'home',\n",
       " 'want',\n",
       " 'lor',\n",
       " 'need',\n",
       " 'sorry',\n",
       " 'don',\n",
       " 'da',\n",
       " 'today',\n",
       " 'later',\n",
       " 'dont',\n",
       " 'send',\n",
       " 'did',\n",
       " 'think',\n",
       " 'tell',\n",
       " 'free',\n",
       " 'txt',\n",
       " '_url_',\n",
       " 'mobile',\n",
       " 'stop',\n",
       " 'text',\n",
       " 'claim',\n",
       " 'reply',\n",
       " 'prize',\n",
       " 'won',\n",
       " 'cash',\n",
       " 'nokia',\n",
       " 'win',\n",
       " 'new',\n",
       " 'urgent',\n",
       " 'week',\n",
       " 'tone',\n",
       " 'box',\n",
       " 'msg',\n",
       " 'service',\n",
       " 'contact',\n",
       " 'guaranteed',\n",
       " 'ppm',\n",
       " 'customer',\n",
       " 'mins',\n",
       " 'phone',\n",
       " 'length']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# TODO: Define TensorFlow columns\n",
    "columns = relevant_vec.get_feature_names()\n",
    "columns.append('length')\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='_num_', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='gt', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='lt', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='just', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='ok', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='ll', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='ur', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='know', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='good', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='got', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='like', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='come', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='day', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='time', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='love', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='going', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='home', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='want', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='lor', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='need', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='sorry', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='don', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='da', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='today', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='later', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='dont', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='send', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='did', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='think', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='tell', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='free', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='txt', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='_url_', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='mobile', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='stop', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='text', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='claim', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='reply', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='prize', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='won', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='cash', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='nokia', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='win', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='new', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='urgent', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='week', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='tone', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='box', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='msg', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='service', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='contact', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='guaranteed', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='ppm', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='customer', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='mins', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='phone', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='length', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_feature_columns = []\n",
    "for key in columns:\n",
    "    my_feature_columns.append(tf.feature_column.numeric_column(key=key))\n",
    "my_feature_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "53480cc47a40475a79aa0d3620e59403",
     "grade": false,
     "grade_id": "cell-299071a3a5c0c39b",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Step 4.2. Setting up Features\n",
    "\n",
    "Create a function `input_fn` that takes parameters `x` (2D numpy array of features) and `y` (1D numpy array of labels).  This should create a tensor for each **column** of the 2D array `x`. You can think of this as creating a tensor for each feature. This function should return a tuple of the dictionary of the tensors created from the columns and a tensor created from the second input `y`.  \n",
    "\n",
    "Create a function `test_input_fn` that takes no arguments, but returns the output of passing in the test set and labels to `input_fn`. Create a similar function `train_input_fn` that does the same thing except passes in the training set and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn(features, labels):\n",
    "#     features_df = pd.DataFrame(features,columns=columns)\n",
    "#     labels_df = pd.DataFrame(labels)\n",
    "#     dataset = tf.data.Dataset.from_tensor_slices((dict(features_df), labels_df))\n",
    "#     dataset = dataset.batch(64)\n",
    "    features_dict = {}\n",
    "    i = 0\n",
    "    for key in columns:\n",
    "        features_dict[key] = tf.constant(features[:,i])\n",
    "        i += 1\n",
    "    \n",
    "    return features_dict, tf.constant(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "23ccccf9897f0de40a281061b996d98a",
     "grade": false,
     "grade_id": "cell-c168fe6645253515",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "def train_input_fn():\n",
    "    return input_fn(X_train, y_train)\n",
    "def test_input_fn():\n",
    "    return input_fn(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "d8ab31c75176be9cf29ce98d2d026001",
     "grade": false,
     "grade_id": "cell-435593e0c65f1c31",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "## Step 4.3 Construct, Train, Evaluate, Results in TensorFlow\n",
    "\n",
    "### Step 4.3.1\n",
    "\n",
    "Construct a DNNClassifier with two hidden layers of 5 units each and store it as `dnn_55`. For reference, [here](https://www.tensorflow.org/get_started/premade_estimators) is an example of using a DNNClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "8c0505c652974b35f90c1298092535a1",
     "grade": false,
     "grade_id": "cell-fc3bb86e8a36d85a",
     "locked": false,
     "schema_version": 1,
     "solution": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmp09p6tgqp\n",
      "INFO:tensorflow:Using config: {'_task_type': 'worker', '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc8b497f550>, '_model_dir': '/tmp/tmp09p6tgqp', '_log_step_count_steps': 100, '_protocol': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_train_distribute': None, '_save_checkpoints_secs': 600, '_master': '', '_save_checkpoints_steps': None, '_num_worker_replicas': 1, '_save_summary_steps': 100, '_tf_random_seed': None, '_experimental_distribute': None, '_task_id': 0, '_device_fn': None, '_is_chief': True, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_num_ps_replicas': 0, '_eval_distribute': None, '_service': None, '_global_id_in_cluster': 0}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Create DNNClassifier\n",
    "tf.set_random_seed(42)\n",
    "dnn_55 = tf.estimator.DNNClassifier(feature_columns=my_feature_columns,hidden_units=[5, 5],n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "6efad4f1783d129cca038fc84399078f",
     "grade": false,
     "grade_id": "cell-7d5e9676e039f413",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Step 4.3.2\n",
    "\n",
    "Construct a LinearClassifier here and store it as `tf_lin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "e2889be2dfe360d12007e4c96b8ecaae",
     "grade": false,
     "grade_id": "cell-6185b7089c072387",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpla66n0ej\n",
      "INFO:tensorflow:Using config: {'_task_type': 'worker', '_keep_checkpoint_max': 5, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fc8b497f4a8>, '_model_dir': '/tmp/tmpla66n0ej', '_log_step_count_steps': 100, '_protocol': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_train_distribute': None, '_save_checkpoints_secs': 600, '_master': '', '_save_checkpoints_steps': None, '_num_worker_replicas': 1, '_save_summary_steps': 100, '_tf_random_seed': None, '_experimental_distribute': None, '_task_id': 0, '_device_fn': None, '_is_chief': True, '_keep_checkpoint_every_n_hours': 10000, '_evaluation_master': '', '_num_ps_replicas': 0, '_eval_distribute': None, '_service': None, '_global_id_in_cluster': 0}\n"
     ]
    }
   ],
   "source": [
    "# TODO: Construct your LinearClassifier here.\n",
    "tf.set_random_seed(42)\n",
    "tf_lin = tf.estimator.LinearClassifier(feature_columns=my_feature_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "1a45bd6ef242260dbf9c36ba1ac9f993",
     "grade": false,
     "grade_id": "cell-5b044b3360272cbd",
     "locked": true,
     "schema_version": 1,
     "solution": false
    }
   },
   "source": [
    "### Step 4.3.3\n",
    "\n",
    "Write a function `train_evaluate(m, num_steps)` that takes the model and a number of steps as arguments, trains the model over the training data, evaluates on the test data, sorts the results of the evaluate operation by key, prints the keys and their values, and returns the accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "checksum": "5bce51824221651a0c5c20573eb85a63",
     "grade": false,
     "grade_id": "cell-0796d795c3acc4d3",
     "locked": false,
     "schema_version": 1,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Write your train_evaluate(m, num_steps) function here.\n",
    "def train_evaluate(m, num_steps):\n",
    "    m.train(input_fn=train_input_fn,steps=num_steps)\n",
    "    eval_result = m.evaluate(input_fn=test_input_fn, steps=num_steps)\n",
    "    print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**eval_result))\n",
    "    return eval_result['accuracy']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "5e9def732f909176f7b11d74c549dfeb",
     "grade": true,
     "grade_id": "cell-bb2ad85a1fab921b",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmp09p6tgqp/model.ckpt.\n",
      "INFO:tensorflow:loss = 3074.1306, step = 1\n",
      "INFO:tensorflow:global_step/sec: 277.24\n",
      "INFO:tensorflow:loss = 254.33302, step = 101 (0.362 sec)\n",
      "INFO:tensorflow:global_step/sec: 359.802\n",
      "INFO:tensorflow:loss = 219.14915, step = 201 (0.278 sec)\n",
      "INFO:tensorflow:global_step/sec: 333.959\n",
      "INFO:tensorflow:loss = 203.02982, step = 301 (0.301 sec)\n",
      "INFO:tensorflow:global_step/sec: 373.967\n",
      "INFO:tensorflow:loss = 193.5601, step = 401 (0.266 sec)\n",
      "INFO:tensorflow:global_step/sec: 326.762\n",
      "INFO:tensorflow:loss = 186.94994, step = 501 (0.310 sec)\n",
      "INFO:tensorflow:global_step/sec: 312.074\n",
      "INFO:tensorflow:loss = 182.31215, step = 601 (0.318 sec)\n",
      "INFO:tensorflow:global_step/sec: 343.787\n",
      "INFO:tensorflow:loss = 178.5488, step = 701 (0.289 sec)\n",
      "INFO:tensorflow:global_step/sec: 355.038\n",
      "INFO:tensorflow:loss = 175.80753, step = 801 (0.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 352.429\n",
      "INFO:tensorflow:loss = 173.6629, step = 901 (0.284 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmp09p6tgqp/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 170.48712.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-28-22:27:23\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmp09p6tgqp/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [100/1000]\n",
      "INFO:tensorflow:Evaluation [200/1000]\n",
      "INFO:tensorflow:Evaluation [300/1000]\n",
      "INFO:tensorflow:Evaluation [400/1000]\n",
      "INFO:tensorflow:Evaluation [500/1000]\n",
      "INFO:tensorflow:Evaluation [600/1000]\n",
      "INFO:tensorflow:Evaluation [700/1000]\n",
      "INFO:tensorflow:Evaluation [800/1000]\n",
      "INFO:tensorflow:Evaluation [900/1000]\n",
      "INFO:tensorflow:Evaluation [1000/1000]\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-28-22:27:31\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.97309417, accuracy_baseline = 0.8654709, auc = 0.9694439, auc_precision_recall = 0.93737984, average_loss = 0.13659061, global_step = 1000, label/mean = 0.13452914, loss = 152.29854, precision = 0.9347826, prediction/mean = 0.13050099, recall = 0.86\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /tmp/tmp09p6tgqp/model.ckpt-1000\n",
      "\n",
      "Test set accuracy: 0.973\n",
      "\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpla66n0ej/model.ckpt.\n",
      "INFO:tensorflow:loss = 3089.3513, step = 1\n",
      "INFO:tensorflow:global_step/sec: 130.18\n",
      "INFO:tensorflow:loss = 476.1765, step = 101 (0.770 sec)\n",
      "INFO:tensorflow:global_step/sec: 430.298\n",
      "INFO:tensorflow:loss = 388.48193, step = 201 (0.232 sec)\n",
      "INFO:tensorflow:global_step/sec: 415.756\n",
      "INFO:tensorflow:loss = 355.36273, step = 301 (0.242 sec)\n",
      "INFO:tensorflow:global_step/sec: 436.179\n",
      "INFO:tensorflow:loss = 338.25455, step = 401 (0.227 sec)\n",
      "INFO:tensorflow:global_step/sec: 462.7\n",
      "INFO:tensorflow:loss = 327.98196, step = 501 (0.217 sec)\n",
      "INFO:tensorflow:global_step/sec: 473.421\n",
      "INFO:tensorflow:loss = 321.22192, step = 601 (0.215 sec)\n",
      "INFO:tensorflow:global_step/sec: 380.234\n",
      "INFO:tensorflow:loss = 316.48383, step = 701 (0.259 sec)\n",
      "INFO:tensorflow:global_step/sec: 446.319\n",
      "INFO:tensorflow:loss = 313.00403, step = 801 (0.224 sec)\n",
      "INFO:tensorflow:global_step/sec: 501.347\n",
      "INFO:tensorflow:loss = 310.35318, step = 901 (0.200 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into /tmp/tmpla66n0ej/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 308.2917.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "WARNING:tensorflow:Trapezoidal rule is known to produce incorrect PR-AUCs; please switch to \"careful_interpolation\" instead.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-11-28-22:27:43\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmpla66n0ej/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [100/1000]\n",
      "INFO:tensorflow:Evaluation [200/1000]\n",
      "INFO:tensorflow:Evaluation [300/1000]\n",
      "INFO:tensorflow:Evaluation [400/1000]\n",
      "INFO:tensorflow:Evaluation [500/1000]\n",
      "INFO:tensorflow:Evaluation [600/1000]\n",
      "INFO:tensorflow:Evaluation [700/1000]\n",
      "INFO:tensorflow:Evaluation [800/1000]\n",
      "INFO:tensorflow:Evaluation [900/1000]\n",
      "INFO:tensorflow:Evaluation [1000/1000]\n",
      "INFO:tensorflow:Finished evaluation at 2018-11-28-22:27:53\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.9748879, accuracy_baseline = 0.8654709, auc = 0.9769568, auc_precision_recall = 0.9456226, average_loss = 0.096756, global_step = 1000, label/mean = 0.13452914, loss = 107.882935, precision = 0.942029, prediction/mean = 0.13451025, recall = 0.8666667\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: /tmp/tmpla66n0ej/model.ckpt-1000\n",
      "\n",
      "Test set accuracy: 0.975\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Param</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DNN</td>\n",
       "      <td>Hidden=(5,5)</td>\n",
       "      <td>0.973094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lin</td>\n",
       "      <td></td>\n",
       "      <td>0.974888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Classifier         Param     Score\n",
       "0        DNN  Hidden=(5,5)  0.973094\n",
       "1        Lin                0.974888"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Results, as a list of dictionaries\n",
    "classifier_results = []\n",
    "\n",
    "classifier_results.append({'Classifier': 'DNN', 'Param': 'Hidden=(5,5)', 'Score': train_evaluate(dnn_55, 1000)})\n",
    "classifier_results.append({'Classifier': 'Lin', 'Param': '',             'Score': train_evaluate(tf_lin, 1000)})\n",
    "\n",
    "display(pd.DataFrame(classifier_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "checksum": "2a508d18c90452e9f6cd2792acc7a345",
     "grade": true,
     "grade_id": "cell-66e0e93c4ef75d6a",
     "locked": true,
     "points": 5,
     "schema_version": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# Don't delete this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
